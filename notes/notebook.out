\BOOKMARK [0][]{chapter.1}{1 Introduction}{}% 1
\BOOKMARK [1][]{section.1.1}{1.1 About this Notebook}{chapter.1}% 2
\BOOKMARK [1][]{section.1.2}{1.2 Policy of Use}{chapter.1}% 3
\BOOKMARK [0][]{chapter.2}{2 Mathematics Basics}{}% 4
\BOOKMARK [1][]{section.2.1}{2.1 Probability}{chapter.2}% 5
\BOOKMARK [2][]{subsection.2.1.1}{2.1.1 Basic Rules}{section.2.1}% 6
\BOOKMARK [2][]{subsection.2.1.2}{2.1.2 Common Probability Distributions}{section.2.1}% 7
\BOOKMARK [1][]{section.2.2}{2.2 Linear Algebra}{chapter.2}% 8
\BOOKMARK [1][]{section.2.3}{2.3 Calculus}{chapter.2}% 9
\BOOKMARK [1][]{section.2.4}{2.4 Informatics}{chapter.2}% 10
\BOOKMARK [1][]{section.2.5}{2.5 Optimization}{chapter.2}% 11
\BOOKMARK [0][]{chapter.3}{3 Machine Learning Basics}{}% 12
\BOOKMARK [1][]{section.3.1}{3.1 Regularization}{chapter.3}% 13
\BOOKMARK [2][]{subsection.3.1.1}{3.1.1 Under-fitting \046 Over-fitting}{section.3.1}% 14
\BOOKMARK [2][]{subsection.3.1.2}{3.1.2 Bias \046 Variance}{section.3.1}% 15
\BOOKMARK [2][]{subsection.3.1.3}{3.1.3 Vector Norm}{section.3.1}% 16
\BOOKMARK [2][]{subsection.3.1.4}{3.1.4 Penalize Complexity}{section.3.1}% 17
\BOOKMARK [1][]{section.3.2}{3.2 Cross-Validation}{chapter.3}% 18
\BOOKMARK [1][]{section.3.3}{3.3 Bayesian Learning}{chapter.3}% 19
\BOOKMARK [2][]{subsection.3.3.1}{3.3.1 Bayes' Rule Terminology}{section.3.3}% 20
\BOOKMARK [2][]{subsection.3.3.2}{3.3.2 Maximum Likelihood}{section.3.3}% 21
\BOOKMARK [2][]{subsection.3.3.3}{3.3.3 Maximum a Posterior \(MAP\)}{section.3.3}% 22
\BOOKMARK [2][]{subsection.3.3.4}{3.3.4 Bayesian Approach}{section.3.3}% 23
\BOOKMARK [2][]{subsection.3.3.5}{3.3.5 Example: Univariate Normal Distribution}{section.3.3}% 24
\BOOKMARK [2][]{subsection.3.3.6}{3.3.6 Example: Categorical Distribution}{section.3.3}% 25
\BOOKMARK [1][]{section.3.4}{3.4 Machine Learning Models}{chapter.3}% 26
\BOOKMARK [2][]{subsection.3.4.1}{3.4.1 Learning and Inference}{section.3.4}% 27
\BOOKMARK [2][]{subsection.3.4.2}{3.4.2 Three Types of Model}{section.3.4}% 28
\BOOKMARK [2][]{subsection.3.4.3}{3.4.3 Example: Regression}{section.3.4}% 29
\BOOKMARK [2][]{subsection.3.4.4}{3.4.4 Example: Classification}{section.3.4}% 30
\BOOKMARK [0][]{chapter.4}{4 Regression}{}% 31
\BOOKMARK [1][]{section.4.1}{4.1 Linear Regression}{chapter.4}% 32
\BOOKMARK [1][]{section.4.2}{4.2 Non-linear Regression}{chapter.4}% 33
\BOOKMARK [1][]{section.4.3}{4.3 Kernel Trick \046 Gaussian Processes}{chapter.4}% 34
\BOOKMARK [1][]{section.4.4}{4.4 Sparse Linear Regression}{chapter.4}% 35
\BOOKMARK [1][]{section.4.5}{4.5 Dual Linear Regression}{chapter.4}% 36
\BOOKMARK [1][]{section.4.6}{4.6 Relevance Vector Regression}{chapter.4}% 37
\BOOKMARK [0][]{chapter.5}{5 Classification}{}% 38
\BOOKMARK [1][]{section.5.1}{5.1 Logistic Regression}{chapter.5}% 39
\BOOKMARK [1][]{section.5.2}{5.2 Non-linear Logistic Regression}{chapter.5}% 40
\BOOKMARK [1][]{section.5.3}{5.3 Kernel Trick \046 Gaussian Process Classification}{chapter.5}% 41
\BOOKMARK [1][]{section.5.4}{5.4 Multi-class Classification}{chapter.5}% 42
\BOOKMARK [0][]{chapter.6}{6 Support Vector Machines}{}% 43
\BOOKMARK [1][]{section.6.1}{6.1 Geometric Margins}{chapter.6}% 44
\BOOKMARK [1][]{section.6.2}{6.2 Primal \046 Dual Problems}{chapter.6}% 45
\BOOKMARK [1][]{section.6.3}{6.3 Support Vectors}{chapter.6}% 46
\BOOKMARK [1][]{section.6.4}{6.4 Slack Variables}{chapter.6}% 47
\BOOKMARK [1][]{section.6.5}{6.5 Hinge Loss}{chapter.6}% 48
\BOOKMARK [1][]{section.6.6}{6.6 Non-linear SVMs}{chapter.6}% 49
\BOOKMARK [1][]{section.6.7}{6.7 Kernel Trick}{chapter.6}% 50
\BOOKMARK [0][]{chapter.7}{7 EM Algorithm}{}% 51
\BOOKMARK [1][]{section.7.1}{7.1 Expectation Maximization}{chapter.7}% 52
\BOOKMARK [1][]{section.7.2}{7.2 Example: Mixture of Gaussians}{chapter.7}% 53
\BOOKMARK [1][]{section.7.3}{7.3 Example: t-distributions}{chapter.7}% 54
\BOOKMARK [1][]{section.7.4}{7.4 Example: Factor Analysis}{chapter.7}% 55
\BOOKMARK [0][]{chapter.8}{8 Boosting}{}% 56
\BOOKMARK [1][]{section.8.1}{8.1 Ensemble Methods}{chapter.8}% 57
\BOOKMARK [1][]{section.8.2}{8.2 Bagging}{chapter.8}% 58
\BOOKMARK [1][]{section.8.3}{8.3 Boosting}{chapter.8}% 59
\BOOKMARK [1][]{section.8.4}{8.4 Adaboost}{chapter.8}% 60
\BOOKMARK [0][]{chapter.9}{9 Decision Tree \046 Random Forest}{}% 61
\BOOKMARK [1][]{section.9.1}{9.1 CART}{chapter.9}% 62
\BOOKMARK [1][]{section.9.2}{9.2 ID3}{chapter.9}% 63
\BOOKMARK [1][]{section.9.3}{9.3 C4.5}{chapter.9}% 64
\BOOKMARK [1][]{section.9.4}{9.4 Random Forest}{chapter.9}% 65
\BOOKMARK [0][]{chapter.10}{10 Graphical Models \046 Markov Network}{}% 66
\BOOKMARK [1][]{section.10.1}{10.1 Graph Definitions}{chapter.10}% 67
\BOOKMARK [1][]{section.10.2}{10.2 Belief Networks}{chapter.10}% 68
\BOOKMARK [1][]{section.10.3}{10.3 Markov Networks}{chapter.10}% 69
\BOOKMARK [1][]{section.10.4}{10.4 Markov Chains}{chapter.10}% 70
\BOOKMARK [1][]{section.10.5}{10.5 Hidden Markov Models}{chapter.10}% 71
\BOOKMARK [0][]{section.10.5}{Bibliography}{}% 72
\BOOKMARK [0][]{appendix.A}{A Statistical Assessment}{}% 73
\BOOKMARK [1][]{section.A.1}{A.1 Hypothesis Testing}{appendix.A}% 74
\BOOKMARK [1][]{section.A.2}{A.2 Confidence Intervals}{appendix.A}% 75
