\BOOKMARK [0][]{chapter.1}{1 Introduction}{}% 1
\BOOKMARK [1][]{section.1.1}{1.1 About this Notebook}{chapter.1}% 2
\BOOKMARK [1][]{section.1.2}{1.2 Policy of Use}{chapter.1}% 3
\BOOKMARK [0][]{chapter.2}{2 Mathematics Basics}{}% 4
\BOOKMARK [1][]{section.2.1}{2.1 Probability}{chapter.2}% 5
\BOOKMARK [2][]{subsection.2.1.1}{2.1.1 Basic Rules}{section.2.1}% 6
\BOOKMARK [2][]{subsection.2.1.2}{2.1.2 Common Probability Distributions}{section.2.1}% 7
\BOOKMARK [1][]{section.2.2}{2.2 Linear Algebra}{chapter.2}% 8
\BOOKMARK [2][]{subsection.2.2.1}{2.2.1 Vectors}{section.2.2}% 9
\BOOKMARK [2][]{subsection.2.2.2}{2.2.2 Matrices \(Square Matrices\)}{section.2.2}% 10
\BOOKMARK [1][]{section.2.3}{2.3 Calculus}{chapter.2}% 11
\BOOKMARK [2][]{subsection.2.3.1}{2.3.1 Differentiation}{section.2.3}% 12
\BOOKMARK [2][]{subsection.2.3.2}{2.3.2 Integration}{section.2.3}% 13
\BOOKMARK [2][]{subsection.2.3.3}{2.3.3 Multivariate Calculus}{section.2.3}% 14
\BOOKMARK [2][]{subsection.2.3.4}{2.3.4 Matrix Calculus}{section.2.3}% 15
\BOOKMARK [2][]{subsection.2.3.5}{2.3.5 Backpropagation Modules}{section.2.3}% 16
\BOOKMARK [1][]{section.2.4}{2.4 Information Theory}{chapter.2}% 17
\BOOKMARK [2][]{subsection.2.4.1}{2.4.1 Self-information}{section.2.4}% 18
\BOOKMARK [2][]{subsection.2.4.2}{2.4.2 Entropy}{section.2.4}% 19
\BOOKMARK [2][]{subsection.2.4.3}{2.4.3 Kullback-Leibler \(KL\) Divergence}{section.2.4}% 20
\BOOKMARK [2][]{subsection.2.4.4}{2.4.4 Cross-entropy}{section.2.4}% 21
\BOOKMARK [1][]{section.2.5}{2.5 Optimization}{chapter.2}% 22
\BOOKMARK [2][]{subsection.2.5.1}{2.5.1 One-dimensional Minimization}{section.2.5}% 23
\BOOKMARK [2][]{subsection.2.5.2}{2.5.2 Gradient Descent}{section.2.5}% 24
\BOOKMARK [2][]{subsection.2.5.3}{2.5.3 Quadratic Functions}{section.2.5}% 25
\BOOKMARK [2][]{subsection.2.5.4}{2.5.4 General Functions}{section.2.5}% 26
\BOOKMARK [2][]{subsection.2.5.5}{2.5.5 Optimization with Constraints}{section.2.5}% 27
\BOOKMARK [0][]{chapter.3}{3 Machine Learning Basics}{}% 28
\BOOKMARK [1][]{section.3.1}{3.1 Regularization}{chapter.3}% 29
\BOOKMARK [2][]{subsection.3.1.1}{3.1.1 Under-fitting \046 Over-fitting}{section.3.1}% 30
\BOOKMARK [2][]{subsection.3.1.2}{3.1.2 Bias \046 Variance}{section.3.1}% 31
\BOOKMARK [2][]{subsection.3.1.3}{3.1.3 Vector Norm}{section.3.1}% 32
\BOOKMARK [2][]{subsection.3.1.4}{3.1.4 Penalize Complexity}{section.3.1}% 33
\BOOKMARK [1][]{section.3.2}{3.2 Cross-Validation}{chapter.3}% 34
\BOOKMARK [1][]{section.3.3}{3.3 Bayesian Learning}{chapter.3}% 35
\BOOKMARK [2][]{subsection.3.3.1}{3.3.1 Bayes' Rule Terminology}{section.3.3}% 36
\BOOKMARK [2][]{subsection.3.3.2}{3.3.2 Maximum Likelihood}{section.3.3}% 37
\BOOKMARK [2][]{subsection.3.3.3}{3.3.3 Maximum a Posterior \(MAP\)}{section.3.3}% 38
\BOOKMARK [2][]{subsection.3.3.4}{3.3.4 Bayesian Approach}{section.3.3}% 39
\BOOKMARK [2][]{subsection.3.3.5}{3.3.5 Example: Univariate Normal Distribution}{section.3.3}% 40
\BOOKMARK [2][]{subsection.3.3.6}{3.3.6 Example: Categorical Distribution}{section.3.3}% 41
\BOOKMARK [1][]{section.3.4}{3.4 Machine Learning Models}{chapter.3}% 42
\BOOKMARK [2][]{subsection.3.4.1}{3.4.1 Learning and Inference}{section.3.4}% 43
\BOOKMARK [2][]{subsection.3.4.2}{3.4.2 Three Types of Model}{section.3.4}% 44
\BOOKMARK [2][]{subsection.3.4.3}{3.4.3 Example: Regression}{section.3.4}% 45
\BOOKMARK [2][]{subsection.3.4.4}{3.4.4 Example: Classification}{section.3.4}% 46
\BOOKMARK [1][]{section.3.5}{3.5 Overview of Common Algorithms}{chapter.3}% 47
\BOOKMARK [0][]{chapter.4}{4 Matrix Factorization}{}% 48
\BOOKMARK [1][]{section.4.1}{4.1 Principal Component Analysis \(PCA\)}{chapter.4}% 49
\BOOKMARK [2][]{subsection.4.1.1}{4.1.1 The PCA Algorithm}{section.4.1}% 50
\BOOKMARK [2][]{subsection.4.1.2}{4.1.2 PCA Interpretation}{section.4.1}% 51
\BOOKMARK [1][]{section.4.2}{4.2 SVD}{chapter.4}% 52
\BOOKMARK [1][]{section.4.3}{4.3 \(N\)NMF}{chapter.4}% 53
\BOOKMARK [0][]{chapter.5}{5 K-Nearest Neighbors}{}% 54
\BOOKMARK [1][]{section.5.1}{5.1 Simple K-NN}{chapter.5}% 55
\BOOKMARK [1][]{section.5.2}{5.2 Fast K-NN Computation}{chapter.5}% 56
\BOOKMARK [0][]{chapter.6}{6 Linear Regression}{}% 57
\BOOKMARK [1][]{section.6.1}{6.1 Basic Model}{chapter.6}% 58
\BOOKMARK [1][]{section.6.2}{6.2 Bayesian Regression}{chapter.6}% 59
\BOOKMARK [1][]{section.6.3}{6.3 Non-linear Regression}{chapter.6}% 60
\BOOKMARK [1][]{section.6.4}{6.4 Kernel Trick \046 Gaussian Processes}{chapter.6}% 61
\BOOKMARK [1][]{section.6.5}{6.5 Sparse Linear Regression}{chapter.6}% 62
\BOOKMARK [1][]{section.6.6}{6.6 Dual Linear Regression}{chapter.6}% 63
\BOOKMARK [1][]{section.6.7}{6.7 Relevance Vector Regression}{chapter.6}% 64
\BOOKMARK [0][]{chapter.7}{7 Logistic Regression}{}% 65
\BOOKMARK [1][]{section.7.1}{7.1 Logistic Regression}{chapter.7}% 66
\BOOKMARK [1][]{section.7.2}{7.2 Non-linear Logistic Regression}{chapter.7}% 67
\BOOKMARK [1][]{section.7.3}{7.3 Kernel Trick \046 Gaussian Process Classification}{chapter.7}% 68
\BOOKMARK [1][]{section.7.4}{7.4 Multi-class Classification}{chapter.7}% 69
\BOOKMARK [0][]{chapter.8}{8 Support Vector Machines}{}% 70
\BOOKMARK [1][]{section.8.1}{8.1 Geometric Margins}{chapter.8}% 71
\BOOKMARK [1][]{section.8.2}{8.2 Primal \046 Dual Problems}{chapter.8}% 72
\BOOKMARK [1][]{section.8.3}{8.3 Support Vectors}{chapter.8}% 73
\BOOKMARK [1][]{section.8.4}{8.4 Slack Variables}{chapter.8}% 74
\BOOKMARK [1][]{section.8.5}{8.5 Hinge Loss}{chapter.8}% 75
\BOOKMARK [1][]{section.8.6}{8.6 Non-linear SVMs}{chapter.8}% 76
\BOOKMARK [1][]{section.8.7}{8.7 Kernel Trick}{chapter.8}% 77
\BOOKMARK [0][]{chapter.9}{9 EM Algorithm}{}% 78
\BOOKMARK [1][]{section.9.1}{9.1 Expectation Maximization}{chapter.9}% 79
\BOOKMARK [1][]{section.9.2}{9.2 Example: Mixture of Gaussians}{chapter.9}% 80
\BOOKMARK [1][]{section.9.3}{9.3 Example: t-distributions}{chapter.9}% 81
\BOOKMARK [1][]{section.9.4}{9.4 Example: Factor Analysis}{chapter.9}% 82
\BOOKMARK [0][]{chapter.10}{10 Bagging \046 Boosting}{}% 83
\BOOKMARK [1][]{section.10.1}{10.1 Ensemble Methods}{chapter.10}% 84
\BOOKMARK [1][]{section.10.2}{10.2 Bagging}{chapter.10}% 85
\BOOKMARK [1][]{section.10.3}{10.3 CART}{chapter.10}% 86
\BOOKMARK [1][]{section.10.4}{10.4 ID3}{chapter.10}% 87
\BOOKMARK [1][]{section.10.5}{10.5 C4.5}{chapter.10}% 88
\BOOKMARK [1][]{section.10.6}{10.6 Random Forest}{chapter.10}% 89
\BOOKMARK [1][]{section.10.7}{10.7 Boosting}{chapter.10}% 90
\BOOKMARK [1][]{section.10.8}{10.8 Adaboost}{chapter.10}% 91
\BOOKMARK [0][]{chapter.11}{11 Clustering}{}% 92
\BOOKMARK [1][]{section.11.1}{11.1 K-Means}{chapter.11}% 93
\BOOKMARK [1][]{section.11.2}{11.2 Spectral Clustering}{chapter.11}% 94
\BOOKMARK [0][]{chapter.12}{12 Graphical Models \046 Markov Network}{}% 95
\BOOKMARK [1][]{section.12.1}{12.1 Graph Definitions}{chapter.12}% 96
\BOOKMARK [2][]{subsection.12.1.1}{12.1.1 Graph}{section.12.1}% 97
\BOOKMARK [2][]{subsection.12.1.2}{12.1.2 Directed Graph}{section.12.1}% 98
\BOOKMARK [2][]{subsection.12.1.3}{12.1.3 Undirected Graph}{section.12.1}% 99
\BOOKMARK [2][]{subsection.12.1.4}{12.1.4 Connectivity}{section.12.1}% 100
\BOOKMARK [2][]{subsection.12.1.5}{12.1.5 Connectedness}{section.12.1}% 101
\BOOKMARK [1][]{section.12.2}{12.2 Belief Networks}{chapter.12}% 102
\BOOKMARK [2][]{subsection.12.2.1}{12.2.1 Definition}{section.12.2}% 103
\BOOKMARK [2][]{subsection.12.2.2}{12.2.2 Uncertain Evidence}{section.12.2}% 104
\BOOKMARK [2][]{subsection.12.2.3}{12.2.3 Independence}{section.12.2}% 105
\BOOKMARK [2][]{subsection.12.2.4}{12.2.4 General Rule for Independence in Belief Networks}{section.12.2}% 106
\BOOKMARK [2][]{subsection.12.2.5}{12.2.5 Markov Equivalence}{section.12.2}% 107
\BOOKMARK [1][]{section.12.3}{12.3 Markov Networks}{chapter.12}% 108
\BOOKMARK [2][]{subsection.12.3.1}{12.3.1 Definition}{section.12.3}% 109
\BOOKMARK [2][]{subsection.12.3.2}{12.3.2 Examples}{section.12.3}% 110
\BOOKMARK [2][]{subsection.12.3.3}{12.3.3 Independence}{section.12.3}% 111
\BOOKMARK [2][]{subsection.12.3.4}{12.3.4 Expressiveness of Markov and Belief Networks}{section.12.3}% 112
\BOOKMARK [2][]{subsection.12.3.5}{12.3.5 Factor Graphs}{section.12.3}% 113
\BOOKMARK [1][]{section.12.4}{12.4 Markov Chains}{chapter.12}% 114
\BOOKMARK [1][]{section.12.5}{12.5 Hidden Markov Models}{chapter.12}% 115
\BOOKMARK [0][]{appendix.A}{A Bayesian Statistics}{}% 116
\BOOKMARK [1][]{section.A.1}{A.1 Bayesian Inference}{appendix.A}% 117
\BOOKMARK [1][]{section.A.2}{A.2 Prior Distributions}{appendix.A}% 118
\BOOKMARK [0][]{appendix.B}{B Statistical Assessment}{}% 119
\BOOKMARK [1][]{section.B.1}{B.1 Hypothesis Testing}{appendix.B}% 120
\BOOKMARK [2][]{subsection.B.1.1}{B.1.1 Testing Basics}{section.B.1}% 121
\BOOKMARK [2][]{subsection.B.1.2}{B.1.2 Testing Procedure}{section.B.1}% 122
\BOOKMARK [2][]{subsection.B.1.3}{B.1.3 Power Investigation}{section.B.1}% 123
\BOOKMARK [2][]{subsection.B.1.4}{B.1.4 Useful Tests}{section.B.1}% 124
\BOOKMARK [1][]{section.B.2}{B.2 Confidence Intervals}{appendix.B}% 125
\BOOKMARK [1][]{section.B.3}{B.3 Bootstrap}{appendix.B}% 126
