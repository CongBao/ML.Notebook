\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}% 
\contentsline {section}{\numberline {1.1}About this Notebook}{1}{section.1.1}% 
\contentsline {section}{\numberline {1.2}Policy of Use}{1}{section.1.2}% 
\contentsline {chapter}{\numberline {2}Mathematics Basics}{2}{chapter.2}% 
\contentsline {section}{\numberline {2.1}Probability}{2}{section.2.1}% 
\contentsline {subsection}{\numberline {2.1.1}Basic Rules}{2}{subsection.2.1.1}% 
\contentsline {paragraph}{Three Axioms of Probability}{2}{section*.2}% 
\contentsline {paragraph}{Joint Probability}{2}{section*.3}% 
\contentsline {paragraph}{Marginalization}{2}{section*.4}% 
\contentsline {paragraph}{Conditional Probibility}{2}{section*.5}% 
\contentsline {paragraph}{Product Rule}{3}{section*.6}% 
\contentsline {paragraph}{Independence}{3}{section*.7}% 
\contentsline {paragraph}{Baye's Rule}{3}{section*.8}% 
\contentsline {paragraph}{Expectation}{3}{section*.9}% 
\contentsline {subsection}{\numberline {2.1.2}Common Probability Distributions}{4}{subsection.2.1.2}% 
\contentsline {paragraph}{Bernoulli}{4}{section*.11}% 
\contentsline {paragraph}{Binomial}{4}{section*.12}% 
\contentsline {paragraph}{Geometric}{4}{section*.13}% 
\contentsline {paragraph}{Negative Binomial}{5}{section*.14}% 
\contentsline {paragraph}{Beta}{5}{section*.15}% 
\contentsline {paragraph}{Poisson}{5}{section*.16}% 
\contentsline {paragraph}{Exponential}{5}{section*.17}% 
\contentsline {paragraph}{Gamma}{5}{section*.18}% 
\contentsline {paragraph}{Categorical}{6}{section*.20}% 
\contentsline {paragraph}{Dirichlet}{6}{section*.21}% 
\contentsline {paragraph}{Univariate Normal}{6}{section*.22}% 
\contentsline {paragraph}{Normal Inverse Gamma}{6}{section*.23}% 
\contentsline {paragraph}{Multivariate Normal}{7}{section*.24}% 
\contentsline {paragraph}{Normal Inverse Wishart}{7}{section*.25}% 
\contentsline {section}{\numberline {2.2}Linear Algebra}{7}{section.2.2}% 
\contentsline {subsection}{\numberline {2.2.1}Vectors}{7}{subsection.2.2.1}% 
\contentsline {paragraph}{Vectors Addition}{7}{section*.26}% 
\contentsline {paragraph}{Vectors Scaling}{7}{section*.27}% 
\contentsline {paragraph}{Rules for Vectors Addition and Scaling}{7}{section*.28}% 
\contentsline {paragraph}{Linear Combination \& Span}{8}{section*.29}% 
\contentsline {paragraph}{Representation of Basis}{8}{section*.30}% 
\contentsline {paragraph}{Linear Dependence}{8}{section*.31}% 
\contentsline {paragraph}{Dot Products}{9}{section*.32}% 
\contentsline {subsection}{\numberline {2.2.2}Matrices (Square Matrices)}{9}{subsection.2.2.2}% 
\contentsline {paragraph}{Linear Transformation}{9}{section*.33}% 
\contentsline {paragraph}{Basic Formulae}{9}{section*.34}% 
\contentsline {paragraph}{Trace}{9}{section*.35}% 
\contentsline {paragraph}{Determinants}{10}{section*.36}% 
\contentsline {paragraph}{Symmetric Matrix}{10}{section*.37}% 
\contentsline {paragraph}{Orthogonal Matrix}{10}{section*.38}% 
\contentsline {paragraph}{Eigendecomposition}{10}{section*.39}% 
\contentsline {paragraph}{Singular Value Decomposition (SVD)}{11}{section*.40}% 
\contentsline {paragraph}{Moore-Penrose Pseudoinverse}{12}{section*.41}% 
\contentsline {section}{\numberline {2.3}Calculus}{12}{section.2.3}% 
\contentsline {subsection}{\numberline {2.3.1}Differentiation}{12}{subsection.2.3.1}% 
\contentsline {paragraph}{Basic Formulae}{12}{section*.42}% 
\contentsline {paragraph}{Mean Value Theorem}{13}{section*.43}% 
\contentsline {paragraph}{Newton's Method}{13}{section*.44}% 
\contentsline {paragraph}{Taylor Series}{13}{section*.45}% 
\contentsline {subsection}{\numberline {2.3.2}Integration}{13}{subsection.2.3.2}% 
\contentsline {paragraph}{Properties}{13}{section*.46}% 
\contentsline {paragraph}{Average Function Value}{14}{section*.47}% 
\contentsline {paragraph}{Jensen's Inequality}{14}{section*.48}% 
\contentsline {subsection}{\numberline {2.3.3}Multivariate Calculus}{14}{subsection.2.3.3}% 
\contentsline {paragraph}{Partial Derivatives}{14}{section*.49}% 
\contentsline {paragraph}{Clairaut's Theorem}{14}{section*.50}% 
\contentsline {paragraph}{Chain Rule}{14}{section*.51}% 
\contentsline {paragraph}{Gradient}{14}{section*.52}% 
\contentsline {paragraph}{Directional Derivative}{15}{section*.53}% 
\contentsline {paragraph}{Lagrange Multipliers}{15}{section*.54}% 
\contentsline {subsection}{\numberline {2.3.4}Matrix Calculus}{15}{subsection.2.3.4}% 
\contentsline {paragraph}{Vector by Scalar}{15}{section*.55}% 
\contentsline {paragraph}{Scalar by Vector (Gradient)}{15}{section*.56}% 
\contentsline {paragraph}{Vector by Vector (Jacobian Matrix)}{15}{section*.57}% 
\contentsline {paragraph}{Matrix by Scalar}{16}{section*.58}% 
\contentsline {paragraph}{Scalar by Matrix (Gradient Matrix)}{16}{section*.59}% 
\contentsline {subsection}{\numberline {2.3.5}Backpropagation Modules}{16}{subsection.2.3.5}% 
\contentsline {paragraph}{Backpropagation}{16}{section*.60}% 
\contentsline {paragraph}{Linear Module}{16}{section*.61}% 
\contentsline {paragraph}{ReLU Module}{16}{section*.62}% 
\contentsline {paragraph}{Softmax Module}{17}{section*.63}% 
\contentsline {paragraph}{Cross-entropy Module}{17}{section*.64}% 
\contentsline {paragraph}{Cross-entropy with Logits Module}{17}{section*.65}% 
\contentsline {section}{\numberline {2.4}Information Theory}{17}{section.2.4}% 
\contentsline {subsection}{\numberline {2.4.1}Self-information}{17}{subsection.2.4.1}% 
\contentsline {subsection}{\numberline {2.4.2}Entropy}{17}{subsection.2.4.2}% 
\contentsline {subsection}{\numberline {2.4.3}Kullback-Leibler (KL) Divergence}{18}{subsection.2.4.3}% 
\contentsline {subsection}{\numberline {2.4.4}Cross-entropy}{18}{subsection.2.4.4}% 
\contentsline {section}{\numberline {2.5}Optimization}{18}{section.2.5}% 
\contentsline {subsection}{\numberline {2.5.1}One-dimensional Minimization}{18}{subsection.2.5.1}% 
\contentsline {paragraph}{Sufficient Conditions for a Minimum}{18}{section*.66}% 
\contentsline {paragraph}{Rate of Convergence}{19}{section*.67}% 
\contentsline {paragraph}{Brackets}{19}{section*.68}% 
\contentsline {subsection}{\numberline {2.5.2}Gradient Descent}{20}{subsection.2.5.2}% 
\contentsline {paragraph}{Exact Line Search Condition}{20}{section*.69}% 
\contentsline {paragraph}{Gradient Descent}{20}{section*.70}% 
\contentsline {subsection}{\numberline {2.5.3}Quadratic Functions}{20}{subsection.2.5.3}% 
\contentsline {paragraph}{Minimizing Quadratic Functions using Line Search}{20}{section*.71}% 
\contentsline {paragraph}{Conjugate Vectors}{21}{section*.72}% 
\contentsline {paragraph}{Gram-Schmidt Procedure}{21}{section*.73}% 
\contentsline {paragraph}{The Conjugate Vectors Algorithm}{22}{section*.74}% 
\contentsline {paragraph}{The Conjugate Gradients Algorithm}{22}{section*.75}% 
\contentsline {paragraph}{Newton Methods}{24}{section*.76}% 
\contentsline {paragraph}{Quasi-Newton Methods}{24}{section*.77}% 
\contentsline {subsection}{\numberline {2.5.4}General Functions}{25}{subsection.2.5.4}% 
\contentsline {subsection}{\numberline {2.5.5}Optimization with Constraints}{26}{subsection.2.5.5}% 
\contentsline {paragraph}{Constraint Types}{26}{section*.78}% 
\contentsline {paragraph}{Transformation Methods}{26}{section*.79}% 
\contentsline {paragraph}{Lagrange Multipliers (Single Constraint)}{27}{section*.80}% 
\contentsline {paragraph}{Lagrange Multipliers (Multiple Constraints)}{27}{section*.81}% 
\contentsline {paragraph}{Computational Approaches to Constrained Optimization}{27}{section*.82}% 
\contentsline {chapter}{\numberline {3}Machine Learning Basics}{28}{chapter.3}% 
\contentsline {section}{\numberline {3.1}Regularization}{28}{section.3.1}% 
\contentsline {subsection}{\numberline {3.1.1}Under-fitting \& Over-fitting}{28}{subsection.3.1.1}% 
\contentsline {subsection}{\numberline {3.1.2}Bias \& Variance}{28}{subsection.3.1.2}% 
\contentsline {subsection}{\numberline {3.1.3}Vector Norm}{28}{subsection.3.1.3}% 
\contentsline {subsection}{\numberline {3.1.4}Penalize Complexity}{29}{subsection.3.1.4}% 
\contentsline {section}{\numberline {3.2}Cross-Validation}{29}{section.3.2}% 
\contentsline {section}{\numberline {3.3}Bayesian Learning}{29}{section.3.3}% 
\contentsline {subsection}{\numberline {3.3.1}Bayes' Rule Terminology}{29}{subsection.3.3.1}% 
\contentsline {subsection}{\numberline {3.3.2}Maximum Likelihood}{30}{subsection.3.3.2}% 
\contentsline {subsection}{\numberline {3.3.3}Maximum a Posterior (MAP)}{30}{subsection.3.3.3}% 
\contentsline {subsection}{\numberline {3.3.4}Bayesian Approach}{30}{subsection.3.3.4}% 
\contentsline {subsection}{\numberline {3.3.5}Example: Univariate Normal Distribution}{31}{subsection.3.3.5}% 
\contentsline {subsection}{\numberline {3.3.6}Example: Categorical Distribution}{33}{subsection.3.3.6}% 
\contentsline {section}{\numberline {3.4}Machine Learning Models}{36}{section.3.4}% 
\contentsline {subsection}{\numberline {3.4.1}Learning and Inference}{36}{subsection.3.4.1}% 
\contentsline {subsection}{\numberline {3.4.2}Three Types of Model}{36}{subsection.3.4.2}% 
\contentsline {subsection}{\numberline {3.4.3}Example: Regression}{37}{subsection.3.4.3}% 
\contentsline {subsection}{\numberline {3.4.4}Example: Classification}{39}{subsection.3.4.4}% 
\contentsline {section}{\numberline {3.5}Overview of Common Algorithms}{40}{section.3.5}% 
\contentsline {chapter}{\numberline {4}Matrix Factorization}{41}{chapter.4}% 
\contentsline {section}{\numberline {4.1}Principal Component Analysis (PCA)}{41}{section.4.1}% 
\contentsline {subsection}{\numberline {4.1.1}The PCA Algorithm}{41}{subsection.4.1.1}% 
\contentsline {subsection}{\numberline {4.1.2}PCA Interpretation}{41}{subsection.4.1.2}% 
\contentsline {section}{\numberline {4.2}Singular Value Decomposition (SVD)}{44}{section.4.2}% 
\contentsline {subsection}{\numberline {4.2.1}The SVD Algorithm}{44}{subsection.4.2.1}% 
\contentsline {subsection}{\numberline {4.2.2}Relation to PCA}{44}{subsection.4.2.2}% 
\contentsline {section}{\numberline {4.3}Non-negative Matrix Factorization ((N)NMF)}{44}{section.4.3}% 
\contentsline {subsection}{\numberline {4.3.1}Standard NMF}{44}{subsection.4.3.1}% 
\contentsline {subsection}{\numberline {4.3.2}Anchor Words Assumption}{45}{subsection.4.3.2}% 
\contentsline {chapter}{\numberline {5}K-Nearest Neighbors}{47}{chapter.5}% 
\contentsline {section}{\numberline {5.1}Simple K-NN}{47}{section.5.1}% 
\contentsline {section}{\numberline {5.2}Fast K-NN Computation}{48}{section.5.2}% 
\contentsline {subsection}{\numberline {5.2.1}Metric Distances Methods}{48}{subsection.5.2.1}% 
\contentsline {paragraph}{Triangle Inequality}{48}{section*.100}% 
\contentsline {paragraph}{Orchard's Algorithm}{48}{section*.101}% 
\contentsline {paragraph}{Approximating and Eliminating Search Algorithm (AESA)}{49}{section*.102}% 
\contentsline {paragraph}{Pre-elimination using Buoys}{49}{section*.103}% 
\contentsline {paragraph}{AESA with Buoys}{49}{section*.104}% 
\contentsline {paragraph}{Orchard with Buoys}{50}{section*.105}% 
\contentsline {subsection}{\numberline {5.2.2}K-dimensional (KD) Tree}{50}{subsection.5.2.2}% 
\contentsline {chapter}{\numberline {6}Linear Regression}{52}{chapter.6}% 
\contentsline {section}{\numberline {6.1}Non-Probability Model}{52}{section.6.1}% 
\contentsline {section}{\numberline {6.2}Probability Model}{52}{section.6.2}% 
\contentsline {section}{\numberline {6.3}Bayesian Regression}{53}{section.6.3}% 
\contentsline {section}{\numberline {6.4}Non-linear Regression}{54}{section.6.4}% 
\contentsline {paragraph}{Basic Idea}{54}{section*.106}% 
\contentsline {paragraph}{Polynomial Regression}{54}{section*.107}% 
\contentsline {paragraph}{Radial Basis Functions (RBF)}{54}{section*.108}% 
\contentsline {paragraph}{Arc Tan Functions}{54}{section*.109}% 
\contentsline {section}{\numberline {6.5}Kernel Trick \& Gaussian Processes}{55}{section.6.5}% 
\contentsline {section}{\numberline {6.6}Sparse Linear Regression}{56}{section.6.6}% 
\contentsline {section}{\numberline {6.7}Dual Linear Regression}{58}{section.6.7}% 
\contentsline {section}{\numberline {6.8}Relevance Vector Regression}{59}{section.6.8}% 
\contentsline {chapter}{\numberline {7}Logistic Regression}{60}{chapter.7}% 
\contentsline {section}{\numberline {7.1}Logistic Regression}{60}{section.7.1}% 
\contentsline {section}{\numberline {7.2}Non-linear Logistic Regression}{60}{section.7.2}% 
\contentsline {section}{\numberline {7.3}Kernel Trick \& Gaussian Process Classification}{60}{section.7.3}% 
\contentsline {section}{\numberline {7.4}Multi-class Classification}{60}{section.7.4}% 
\contentsline {chapter}{\numberline {8}Support Vector Machines}{61}{chapter.8}% 
\contentsline {section}{\numberline {8.1}Geometric Margins}{61}{section.8.1}% 
\contentsline {section}{\numberline {8.2}Primal \& Dual Problems}{61}{section.8.2}% 
\contentsline {section}{\numberline {8.3}Support Vectors}{61}{section.8.3}% 
\contentsline {section}{\numberline {8.4}Slack Variables}{61}{section.8.4}% 
\contentsline {section}{\numberline {8.5}Hinge Loss}{61}{section.8.5}% 
\contentsline {section}{\numberline {8.6}Non-linear SVMs}{61}{section.8.6}% 
\contentsline {section}{\numberline {8.7}Kernel Trick}{61}{section.8.7}% 
\contentsline {chapter}{\numberline {9}EM Algorithm}{62}{chapter.9}% 
\contentsline {section}{\numberline {9.1}Expectation Maximization}{62}{section.9.1}% 
\contentsline {section}{\numberline {9.2}Example: Mixture of Gaussians}{62}{section.9.2}% 
\contentsline {section}{\numberline {9.3}Example: t-distributions}{62}{section.9.3}% 
\contentsline {section}{\numberline {9.4}Example: Factor Analysis}{62}{section.9.4}% 
\contentsline {chapter}{\numberline {10}Bagging \& Boosting}{63}{chapter.10}% 
\contentsline {section}{\numberline {10.1}Ensemble Methods}{63}{section.10.1}% 
\contentsline {section}{\numberline {10.2}Bagging}{63}{section.10.2}% 
\contentsline {section}{\numberline {10.3}CART}{63}{section.10.3}% 
\contentsline {section}{\numberline {10.4}ID3}{63}{section.10.4}% 
\contentsline {section}{\numberline {10.5}C4.5}{63}{section.10.5}% 
\contentsline {section}{\numberline {10.6}Random Forest}{63}{section.10.6}% 
\contentsline {section}{\numberline {10.7}Boosting}{63}{section.10.7}% 
\contentsline {section}{\numberline {10.8}Adaboost}{63}{section.10.8}% 
\contentsline {chapter}{\numberline {11}Clustering}{64}{chapter.11}% 
\contentsline {section}{\numberline {11.1}K-Means}{64}{section.11.1}% 
\contentsline {subsection}{\numberline {11.1.1}The K-Means Algorithm}{64}{subsection.11.1.1}% 
\contentsline {subsection}{\numberline {11.1.2}K-Means Limitations}{65}{subsection.11.1.2}% 
\contentsline {paragraph}{Hard Assignment}{65}{section*.110}% 
\contentsline {paragraph}{Outlier Sensitivity}{65}{section*.111}% 
\contentsline {paragraph}{Shape/Density Issues}{65}{section*.112}% 
\contentsline {paragraph}{Computational Cost}{65}{section*.113}% 
\contentsline {paragraph}{Representation Sensitivity}{65}{section*.114}% 
\contentsline {paragraph}{Missing Data}{65}{section*.115}% 
\contentsline {section}{\numberline {11.2}Spectral Clustering}{65}{section.11.2}% 
\contentsline {subsection}{\numberline {11.2.1}Similarity Graphs}{65}{subsection.11.2.1}% 
\contentsline {paragraph}{$\epsilon $-Neighborhood Graph}{65}{section*.116}% 
\contentsline {paragraph}{$k$-Nearest Neighbor Graphs}{65}{section*.117}% 
\contentsline {paragraph}{Fully Connected Graph}{66}{section*.118}% 
\contentsline {subsection}{\numberline {11.2.2}Graph Laplacian}{66}{subsection.11.2.2}% 
\contentsline {paragraph}{Basic Graph Definitions}{66}{section*.119}% 
\contentsline {paragraph}{Unnormalized Graph Laplacian}{66}{section*.120}% 
\contentsline {paragraph}{Normalized Graph Laplacian}{67}{section*.121}% 
\contentsline {subsection}{\numberline {11.2.3}Spectral Clustering Algorithms}{67}{subsection.11.2.3}% 
\contentsline {subsection}{\numberline {11.2.4}NCut and RatioCut Approximations}{68}{subsection.11.2.4}% 
\contentsline {subsection}{\numberline {11.2.5}Random Walk Viewpoint}{70}{subsection.11.2.5}% 
\contentsline {chapter}{\numberline {12}Graphical Models \& Markov Network}{71}{chapter.12}% 
\contentsline {section}{\numberline {12.1}Graph Definitions}{71}{section.12.1}% 
\contentsline {subsection}{\numberline {12.1.1}Graph}{71}{subsection.12.1.1}% 
\contentsline {subsection}{\numberline {12.1.2}Directed Graph}{71}{subsection.12.1.2}% 
\contentsline {subsection}{\numberline {12.1.3}Undirected Graph}{72}{subsection.12.1.3}% 
\contentsline {subsection}{\numberline {12.1.4}Connectivity}{72}{subsection.12.1.4}% 
\contentsline {subsection}{\numberline {12.1.5}Connectedness}{72}{subsection.12.1.5}% 
\contentsline {section}{\numberline {12.2}Belief Networks}{73}{section.12.2}% 
\contentsline {subsection}{\numberline {12.2.1}Definition}{73}{subsection.12.2.1}% 
\contentsline {subsection}{\numberline {12.2.2}Uncertain Evidence}{73}{subsection.12.2.2}% 
\contentsline {subsection}{\numberline {12.2.3}Independence}{74}{subsection.12.2.3}% 
\contentsline {subsection}{\numberline {12.2.4}General Rule for Independence in Belief Networks}{75}{subsection.12.2.4}% 
\contentsline {subsection}{\numberline {12.2.5}Markov Equivalence}{76}{subsection.12.2.5}% 
\contentsline {section}{\numberline {12.3}Markov Networks}{76}{section.12.3}% 
\contentsline {subsection}{\numberline {12.3.1}Definition}{76}{subsection.12.3.1}% 
\contentsline {subsection}{\numberline {12.3.2}Examples}{76}{subsection.12.3.2}% 
\contentsline {subsection}{\numberline {12.3.3}Independence}{77}{subsection.12.3.3}% 
\contentsline {subsection}{\numberline {12.3.4}Expressiveness of Markov and Belief Networks}{77}{subsection.12.3.4}% 
\contentsline {subsection}{\numberline {12.3.5}Factor Graphs}{77}{subsection.12.3.5}% 
\contentsline {section}{\numberline {12.4}Markov Chains}{77}{section.12.4}% 
\contentsline {section}{\numberline {12.5}Hidden Markov Models}{77}{section.12.5}% 
\contentsline {chapter}{\numberline {A}Bayesian Statistics}{78}{appendix.A}% 
\contentsline {section}{\numberline {A.1}Bayesian Inference}{78}{section.A.1}% 
\contentsline {section}{\numberline {A.2}Prior Distributions}{78}{section.A.2}% 
\contentsline {chapter}{\numberline {B}Statistical Assessment}{79}{appendix.B}% 
\contentsline {section}{\numberline {B.1}Hypothesis Testing}{79}{section.B.1}% 
\contentsline {subsection}{\numberline {B.1.1}Testing Basics}{79}{subsection.B.1.1}% 
\contentsline {subsection}{\numberline {B.1.2}Testing Procedure}{79}{subsection.B.1.2}% 
\contentsline {subsection}{\numberline {B.1.3}Power Investigation}{80}{subsection.B.1.3}% 
\contentsline {subsection}{\numberline {B.1.4}Useful Tests}{80}{subsection.B.1.4}% 
\contentsline {section}{\numberline {B.2}Confidence Intervals}{80}{section.B.2}% 
\contentsline {section}{\numberline {B.3}Bootstrap}{80}{section.B.3}% 
