%!TEX root = ../notebook.tex
% Chapter 12

\chapter{Approximate Inference}
\label{chapter12}



\section{Sampling}
\label{section12.1}

\subsection{Basic Monte Carlo}

Sampling concerns drawing realizations (samples) $\cX=\left\{x^1,\dotsc,x^L\right\}$ of a variable $x$ from a distribution $\P{x}$. For a discrete variable $x$, in the limit of a large number of samples, the fraction of samples in state $\mathsf{x}$ tends to $\P{x=\mathsf{x}}$. That is,
\begin{align*}
\lim_{L\to\infty}\frac{1}{L}\sum_{l=1}^L\bI\left[x^l=\mathsf{x}\right]=\P{x=\mathsf{x}}
\end{align*}
In the continuous case, one can consider a region $R$ such that the probability that samples occupy $R$ tends to the integral of $\P{x}$ over $R$. Given a finite set of samples, one can then approximate expectations using
\begin{align*}
\vecx{f(x)}_{\P{x}}\approx\frac{1}{L}\sum_{l=1}^Lf(x^l)\equiv\hat{f}_\cX
\end{align*}
The subscript in $\hat{f}_\cX$ emphasizes that the approximation is dependent on the set of samples drawn. This sample approximation holds for both discrete and continuous variables.

A sampling procedure produces realizations of the set $\cX$ and can itself be considered as generating a distribution $\ti{P}\left(\cX\right)$. Provided the marginals of the sampling distribution are equal to the marginals of the target distribution, $\ti{P}\left(\cX\right)=\P{x^l}$, then the average of the approximation $\hat{f}_\cX$ with respect to draws of the sample set $\cX$ is
\begin{align*}
\vecx{\hat{f}_\cX}_{\ti{P}\left(\cX\right)}=\frac{1}{L}\sum_{l=1}^L\vecx{f\left(x^l\right)}_{\ti{P}\left(x^l\right)}=\vecx{f(x)}_{\P{x}}
\end{align*}
Hence the mean of the sample approximation is the exact mean of $f$ provided only that the marginals of $\ti{P}\left(\cX\right)$ correspond to $\P{x}$.

For any sampling method, an important issue is the variance of the sample estimate. If this is low then only a small number of samples are required since the sample mean must be close to the true mean (assuming it is unbiased). Defining
\begin{align*}
\De\hat{f}_\cX=\hat{f}_\cX-\vecx{\hat{f}_\cX}_{\ti{P}\left(\cX\right)},\quad \De f(x)=f(x)-\vecx{f(x)}_{\P{x}}
\end{align*}
the variance of the approximation is (assuming $\ti{P}\left(x^l\right)=\P{x^l}$, for all $l$):
\begin{align*}
\vecx{\left[\De\hat{f}_\cX\right]^2}_{\ti{P}\left(\cX\right)}&=\frac{1}{L^2}\sum_{l,l'}\vecx{\De f\left(x^l\right)\De f\left(x^{l'}\right)}_{\ti{P}\left(x^l,x^{l'}\right)} \\
&=\frac{1}{L^2}\left(L\vecx{\left[\De f(x)\right]^2}_{\ti{P}\left(x\right)}+\sum_{l\neq l'}\vecx{\De f\left(x^l\right)\De f\left(x^{l'}\right)}_{\ti{P}\left(x^l,x^{l'}\right)}\right)
\end{align*}
Provided the samples are independent $\ti{P}\left(\cX\right)=\prod_{l=1}^L\ti{P}\left(x^l\right)$ and $\ti{P}\left(x^l,x^{l'}\right)=\P{x^l}\P{x^{l'}}$. The second term in the equation above is composed of $\vecx{\De f\left(x^l\right)}\vecx{f\left(x^{l'}\right)}$ which is zero since $\vecx{\De f(x)}=0$. Hence,
\begin{align*}
\vecx{\left[\De\hat{f}_\cX\right]^2}_{\ti{P}\left(x^l,x^{l'}\right)}=\frac{1}{L}\vecx{\left[\De f(x)\right]^2}_{\P{x}}
\end{align*}
and the variance of the approximation scales inversely with the number of samples. The critical difficulty is in actually generating independent samples from $\P{x}$. A dependent scheme may be unbiased, but if variance is very high we meed a large number of samples to get an accurate approximation.

\subsection{Importance Sampling}

Consider $p(x)=\frac{1}{Z}p^*(x)$, where $p^*(x)$ can be evaluated but $Z=\int_xp^*(x)$ is intractable. The average with respect to $p$ is given by
\begin{align*}
\int_xf(x)p(x)=\frac{\int_xf(x)p^*(x)}{\int_xp^*(x)}=\frac{\int_xf(x)\frac{p^*(x)}{q(x)}q(x)}{\int_x\frac{p^*(x)}{q(x)}q(x)}
\end{align*}
and we can approximate this sampling from $q(x)$.
\begin{align*}
\int_xf(x)p(x)\approx\frac{\sum_{l=1}^Lf(x^l)\frac{p^*(x^l)}{q(x^l)}}{\sum_{l=1}^L\frac{p^*(x^l)}{q(x^l)}}=\sum_{l=1}^Lf(x^l)w^l
\end{align*}
where we define the normalized importance weights
\begin{align*}
w^l=\frac{\pfrac{p^*(x^l)}{q(x^l)}}{\pfrac{\sum_{l=1}^Lp^*(x^l)}{q(x^l)}}
\end{align*}
However, it is not easy to find the right distribution $Q$ and diagnose whether it is good.

\subsection{Rejection Sampling}

Consider that we have an efficient sampling procedure for a distribution $q(x)$. Suppose that we know that $p(x)<cq(x)$ for all $x$. Then we can sample from $q(x)$ and accept the sample with probability $\frac{p(x)}{cq(x)}$.

Let $y\in\{0,1\}$ be an auxiliary binary variable and define $q(x,y)=q(x)q(y|x)$. If we set $q(y=1|x)\prop\pfrac{p(x)}{q(x)}$, then $q(x,y=1)\prop p(x)$. So sampling from $q(x,y)$ gives us a procedure for sampling from $p(x)$. The expected acceptance rate is $1/c$. When working with unnormalized $p^*(x)$, if we find $c$ such that $p^*(x)<cq(x)$. The acceptance rate becomes $Z/c$. However, it is not easy to find distribution $q(x)$ such that $c$ is small.

\subsection{Markov Chain Monte Carlo (MCMC)}

\paragraph{MCMC Idea}

Consider the conditional distribution $q(x^{l+1}|x^l)$. If we are given an initial sample $x^1$, then we can recursively generate samples $x^1,x^2,\dotsc,x^L$. After a long time $L\gg 1$, the samples are from the unique stationary distribution $q_\infty(x)$ which is defined as
\begin{align*}
q_\infty(x')&=\int q(x'|x)q_\infty(x)dx \\
q_\infty(x')&=\sum_xq(x'|x)q_\infty(x)
\end{align*}
for continuous and discrete variable respectively. The idea in MCMC is, for a given distribution $p(x)$, to find a transition $q(x'|x)$ which has $p(x)$ as its stationary distribution. If we can do so, then we can draw samples from the Markov chain by forward sampling and take these as samples from $p(x)$ as the chain converges towards its stationary distribution.

\paragraph{Gibbs Sampling}

Sometimes the whole distribution $p(x)$ is nasty, but the conditionals $p(x_i|x_{\setminus i})$ are easy to sample from. Gibbs sampling is such a method that we loop over the variables (at random or in turn) and sample from the conditional $p(x_i|x_{\setminus i})$.

\paragraph{Metropolis-Hastings Sampling}

Sometimes we cannot sample from the conditionals. The idea of Metropolis algorithm is using some proposal distribution $q(x'|x)$ and we will accept or reject based on density of $p(x)$. We can repeat the following steps starting from some $x$:
\begin{enumerate}
	\item Propose a new state $x'$ by sampling from proposed $q(x'|x)$.
	\item Accept the new state with probability
	\begin{align*}
	\min\left(1,\frac{p(x')q(x|x')}{p(x)q(x'|x)}\right)
	\end{align*}
	\item If the sample is not accepted the old state becomes the new sample.
\end{enumerate}



\section{Expectation Maximization (EM)}
\label{section12.2}

\subsection{Hidden Variables}

In many models some variables are not directly observed, but are latent or ``hidden''. For hidden variables $h$, and visible variables $v$ we still have a well defined likelihood
\begin{align*}
	\p{v|\th}&=\int\p{v,h|\th}dh \\
	\p{v|\th}&=\sum_h\p{v,h|\th}
\end{align*}
for continuous and discrete variable respectively. Our task is to find the parameters $\th$ that optimize $\p{v|\th}$. This task is more numerically complex than in the case when all the variables are visible. Nevertheless, we can perform numerical optimization using any routine we wish to find $\th$.

\subsection{Variational EM}

\paragraph{Lower Bound}

The key feature of the EM algorithm is to form an alternative objective function for which the parameter coupling effect discussed is removed, meaning that individual parameter updates can be achieved, akin to the case of fully observed data. The way this works is to replace the marginal likelihood with a lower bound -- it is this lower bound that has the decoupled form. Consider the KL divergence (which is always non-negative) between a ``variational'' distribution $q(h|v)$ and the parametric model $p(h|v,\th)$.
\begin{align*}
	\KL{q(h|v)}{p(h|v,\th)}\equiv\vecx{\log q(h|v)-\log p(h|v,\th)}_{q(h|v)}\geq 0
\end{align*}
The term ``variational'' refers to the fact that this distribution will be a parameter of an optimization problem. Using $p(h|v,\th)=\pfrac{p(h,v|\th)}{p(v|\th)}$ and the fact that $p(v|\th)$ does not depend on $h$,
\begin{align*}
	\KL{q(h|v)}{p(h|v,\th)}=\vecx{\log q(h|v)}_{q(h|v)}-\vecx{\log p(h,v|\th)}_{q(h|v)}+\log p(v|\th)\geq 0
\end{align*}
Rearranging, we obtain a bound on the marginal likelihood
\begin{align*}
	\log p(v|\th)\geq\ub{-\vecx{\log q(h|v)}_{q(h|v)}}{\text{Entropy}}+\ub{\vecx{\log p(h,v|\th)}_{q(h|v)}}{\text{Energy}}
\end{align*}
The bound is potentially useful since the energy is similar in form to the fully observed case, except that terms with missing data have their log likelihood weighted by a prefactor.

We could rewrite the likelihood introducing auxillary variational distribution $q(h)$:
\begin{align*}
	\log p(v|\th)&=\log\sum_hp(v,h|\th)=\log\sum_h\frac{q(h)}{q(h)}p(v,h|\th)=\log\vecx{\frac{p(v,h|\th)}{q(h)}}_{q(h)} \\
	&\geq\vecx{\log\frac{p(v,h|\th)}{q(h)}}_{q(h)}=\vecx{\log p(v,h|\th)}_{q(h)}+\H{q}
\end{align*}
The inequality sign is achieved due to Jensen's inequality. The final formula is called \emph{evidence lower bound (ELBO)} or \emph{variational free energy}. It is a function $B(q,\th)$ of the parameters of the model and the variational distribution:
\begin{align*}
	B(q,\th)=\vecx{\log p(v,h|\th)}_{q(h)}+\H{q}
\end{align*}

\paragraph{The EM Algorithm}

The EM algorithm is such an approach that we start from some initial guess $\th_0,q_0*h$ and repeat the following steps until convergence:
\begin{enumerate}
	\item E-step: $q_{new}=\argmax_qB(q,\th_{old})$
	\item M-step: $\th_{new}=\argmax_\th B(q_{new},\th)$
\end{enumerate}
In E-step, we can rewrite free energy like this
\begin{align*}
	B(q,\th)=\vecx{\log\frac{p(v,h|\th)}{q(h)}}_{q(h)}=\vecx{\log\frac{p(h|v,\th)p(v|\th)}{q(h)}}_{q(h)}=\log p(v|\th)-\KL{q(h)}{p(h|v,\th)}
\end{align*}
This means that the optimal setting is $q(h)=p(h|v,\th)$, which is also the case that Jensen's inequality reaches the equivalence condition. In M-step we optimize for the new parameters of the model
\begin{align*}
	\th_{new}=\argmax_\th\vecx{\log p(v,h|\th)}_{q(h)}+\H{q}=\argmax_\th\vecx{\log p(v,h|\th)}_{q(h)}
\end{align*}
where $q(h)=p(h|v,\th_{old})$. This means that we are only interested in computing expectations under posterior (rather than the full posterior itself).

We can show that the EM algorithm increases the likelihood. We use $\th'$ for the new parameters, and $\th$ for the previous parameters in two consecutive iterations. Using $q(h)=p(h|v,\th)$ we see that as a function of the parameters, the lower bound depends on $\th$ and $\th'$:
\begin{align*}
	B(\th'|\th)&\equiv-\vecx{\log p(h|v,\th)}_{p(h|v,\th)}+\vecx{\log p(h,v|\th')}_{p(h|v,\th)} \\
	\log p(v|\th')&=B(\th'|\th)+\KL{p(h|v,\th)}{p(h|v,\th')} \\
	\log p(v|\th)&=B(\th|\th)+\ub{\KL{p(h|v,\th)}{p(h|v,\th)}}{0}
\end{align*}
Hence
\begin{align*}
	\log p(v|\th')-\log p(v|\th)=\ub{B(\th'|\th)-B(\th|\th)}{\geq 0}+\ub{\KL{p(h|v,\th)}{p(h|v,\th')}}{\geq 0}\geq 0
\end{align*}
The first assertion is true since, by definition of the M-step, we search for a $\th'$ which has a higher value for the bound than our starting value $\th$.

\subsection{EM Algorithm for Mixture Models}

\paragraph{Mixture of Gaussians (MoG)}

The pdf of MoG is
\begin{align*}
	\P{\vec{x}|\vec{\th}}=\sum_{k=1}^K\la_k\Norm_{\vec{x}}[\vec{\mu}_k,\mat{\Si}_k]
\end{align*}
We can rewrite it as a marginalization form that
\begin{align*}
	\P{\vec{x}|\vec{\th}}&=\sum_{k=1}^K\P{\vec{x},h=k|\vec{\th}} \\
	&=\sum_{k=1}^K\P{\vec{x}|h=k,\vec{\th}}\P{h=k|\vec{\th}}
\end{align*}
And define the distributions
\begin{align*}
	\P{\vec{x}|h,\vec{\th}}&=\Norm_{\vec{x}}[\vec{\mu}_h,\mat{\Si}_h] \\
	\P{h|\vec{\th}}&=\Cat_h[\vec{\la}]
\end{align*}
E-Step -- Maximize bound w.r.t. distribution $q(h)$.
\begin{align*}
	\hat{q}_i(h_i=k)&=\P{h_i=k|\vec{x}_i,\vec{\th}^{(t)}} \\
	&=\frac{\P{\vec{x}_i|h_i=k,\vec{\th}^{(t)}}\P{h_i=k|\vec{\th}^{(t)}}}{\P{\vec{x}_i|\vec{\th}^{(t)}}} \\
	&=\frac{\P{\vec{x}_i|h_i=k,\vec{\th}^{(t)}}\P{h_i=k|\vec{\th}^{(t)}}}{\sum_{j=1}^K\P{\vec{x}_i|h_i=j,\vec{\th}^{(t)}}\P{h_i=j|\vec{\th}^{(t)}}} \\
	&=\frac{\la_k\Norm_{\vec{x}_i}[\vec{\mu}_k,\mat{\Si}_k]}{\sum_{j=1}^K\la_j\Norm_{\vec{x}_i}[\vec{\mu}_j,\mat{\Si}_j]} \\
	&=r_{ik}
\end{align*}
We call $r_{ik}$ the responsibility of the $k\nth$ Gaussian for the $i\nth$ data point. \\
M-Step -- Maximize bound w.r.t. parameters $\vec{\th}$.
\begin{align*}
	\hat{\vec{\th}}^{(t+1)}&=\argmax_{\vec{\th}}\left(\sum_{i=1}^N\sum_{k=1}^K\hat{q}_i(h_i=k)\log\P{\vec{x}_i,h_i=k|\vec{\th}}\right) \\
	&=\argmax_{\vec{\th}}\left(\sum_{i=1}^N\sum_{k=1}^Kr_{ik}\log\left(\la_k\Norm_{\vec{x}_i}[\vec{\mu}_k,\mat{\Si}_k]\right)\right)
\end{align*}
Take derivative, equate to zero and solve
\begin{align*}
	\la_k^{(t+1)}&=\frac{\sum_{i=1}^Nr_{ik}}{\sum_{j=1}^K\sum_{i=1}^Nr_{ij}} \\
	\vec{\mu}_k^{(t+1)}&=\frac{\sum_{i=1}^Nr_{ik}\vec{x}_i}{\sum_{i=1}^Nr_{ik}} \\
	\mat{\Si}_k^{(t+1)}&=\frac{\sum_{i=1}^Nr_{ik}\left(\vec{x}_i-\vec{\mu}_k^{(t+1)}\right)\left(\vec{x}_i-\vec{\mu}_k^{(t+1)}\right)\TT}{\sum_{i=1}^Nr_{ik}}
\end{align*}

\paragraph{Student t-distributions}

The pdf of multivariate t-distribution is
\begin{align*}
	\P{\vec{x}|\vec{\th}}&=\Stud_{\vec{x}}[\vec{\mu},\mat{\Si},\nu] \\
	&=\frac{\Ga\left(\frac{\nu+D}{2}\right)}{(\nu\pi)^{\frac{D}{2}}\det{\mat{\Si}}^\half\Ga\left(\frac{\nu}{2}\right)}\left(1+\frac{(\vec{x}-\vec{\mu})\TT\mat{\Si}\inv(\vec{x}-\vec{\mu})}{\nu}\right)^{-\frac{\nu+D}{2}}
\end{align*}
We can rewrite it as a marginalization form that
\begin{align*}
	\P{\vec{x}|\vec{\th}}&=\int\P{\vec{x},h|\vec{\th}}dh \\
	&=\int\P{\vec{x}|h,\vec{\th}}\P{h|\vec{\th}}dh
\end{align*}
And define the distributions
\begin{align*}
	\P{\vec{x}|h,\vec{\th}}&=\Norm_{\vec{x}}[\vec{\mu},\pfrac{\mat{\Si}}{h}] \\
	\P{h|\vec{\th}}&=\Gam_h[\pfrac{\nu}{2},\pfrac{\nu}{2}]
\end{align*}
E-Step -- Maximize bound w.r.t. distributions $q(h_i)$.
\begin{align*}
	\hat{q}_i(h_i)&=\P{h_i|\vec{x}_i,\vec{\th}^{(t)}} \\
	&=\frac{\P{\vec{x}_i|h_i,\vec{\th}^{(t)}}\P{h_i|\vec{\th}^{(t)}}}{\P{\vec{x}_i|\vec{\th}^{(t)}}} \\
	&=\frac{\Norm_{\vec{x}_i}[\vec{\mu},\mat{\Si}/h_i]\Gam_{h_i}[\nu/2,\nu/2]}{\P{\vec{x}_i|\vec{\th}^{(t)}}} \\
	&=\Gam_{h_i}\left[\frac{\nu+1}{2},\half(\vec{x}_i-\vec{\mu})\TT\mat{\Si}\inv(\vec{x}_i-\vec{\mu})+\frac{\nu}{2}\right]
\end{align*}
Extract expectations
\begin{align*}
	\E{h_i}&=\frac{\nu+D}{\nu+(\vec{x}_i-\vec{\mu})\TT\mat{\Si}\inv(\vec{x}_i-\vec{\mu})} \\
	\E{\log h_i}&=\Ps\left(\frac{\nu+D}{2}\right)-\log\left(\frac{\nu+(\vec{x}_i-\vec{\mu})\TT\mat{\Si}\inv(\vec{x}_i-\vec{\mu})}{2}\right)
\end{align*}
M-Step -- Maximize bound w.r.t. parameters $\vec{\th}$.
\begin{align*}
	\hat{\vec{\th}}^{(t+1)}&=\argmax_{\vec{\th}}\sum_{i=1}^N\int\hat{q}_i(h_i)\log\P{\vec{x}_i,h_i|\vec{\th}}dh_i \\
	&=\argmax_{\vec{\th}}\sum_{i=1}^N\int\hat{q}_i(h_i)\left(\log\P{\vec{x}_i|h_i,\vec{\th}}+\log\P{h_i}\right)dh_i \\
	&=\argmax_{\vec{\th}}\sum_{i=1}^N\int\P{h_i|\vec{x}_i,\vec{\th}^{(t)}}\left(\log\P{\vec{x}_i|h_i,\vec{\th}_i}+\log\P{h_i}\right)dh_i \\
	&=\argmax_{\vec{\th}}\sum_{i=1}^N\E{\log\P{\vec{x}_i|h_i,\vec{\th}}}+\E{\log\P{h_i}}
\end{align*}
where
\begin{align*}
	\E{\log\P{\vec{x}_i|h_i,\vec{\th}}}&=-\frac{D\log 2\pi+\log\det{\mat{\Si}}+\E{\log h_i}+(\vec{x}_i-\vec{\mu})\TT\mat{\Si}\inv(\vec{x}_i-\vec{\mu})\E{h_i}}{2} \\
	\E{\log\P{h_i}}&=\frac{\nu}{2}\log\frac{\nu}{2}-\log\Ga\left(\frac{\nu}{2}\right)+\left(\frac{\nu}{2}-1\right)\E{\log h_i}-\frac{\nu}{2}\E{h_i}
\end{align*}
The updates are
\begin{align*}
	\vec{\mu}^{(t+1)}&=\frac{\sum_{i=1}^N\E{h_i}\vec{x}_i}{\sum_{i=1}^N\E{h_i}} \\
	\mat{\Si}^{(t+1)}&=\frac{\sum_{i=1}^N\E{h_i}\left(\vec{x}_i-\mu^{(t+1)}\right)\left(\vec{x}_i-\mu^{(t+1)}\right)\TT}{\sum_{i=1}^N\E{h_i}}
\end{align*}
There is no closed form solution for $\nu$. One must optimize bound -- since it is only one number we can optimize by just evaluating with a fine grid of values and picking the best.

\paragraph{Factor Analysis}

We want to compromise between full covariance matrix (desirable but many parameters) and diagonal covariance matrix (no modeling of covariance). We model full covariance in a subspace $\mat{\Ph}$ and mops everything else up with diagonal component $\mat{\Si}$:
\begin{align*}
	\P{\vec{x}|\vec{\th}}=\Norm_{\vec{x}}[\vec{\mu},\mat{\Ph}\mat{\Ph}\TT+\mat{\Si}]
\end{align*}
We can rewrite it as a marginalization form that
\begin{align*}
	\P{\vec{x}|\vec{\th}}&=\int\P{\vec{x},\vec{h}|\vec{\th}}d\vec{h} \\
	&=\int\P{\vec{x}|\vec{h},\vec{\th}}\P{\vec{h}|\vec{\th}}d\vec{h}
\end{align*}
And define the distributions
\begin{align*}
	\P{\vec{x}|\vec{h},\vec{\th}}&=\Norm_{\vec{x}}[\vec{\mu}+\mat{\Ph}\vec{h},\mat{\Si}] \\
	\P{\vec{h}}&=\Norm_{\vec{h}}[\vec{0},\mat{I}]
\end{align*}
E-Step -- Maximize bound w.r.t. distribution $q(\vec{h}_i)$.
\begin{align*}
	\hat{q}_i(\vec{h}_i)&=\P{\vec{h}_i|\vec{x}_i,\vec{\th}^{(t)}} \\
	&=\frac{\P{\vec{x}_i|\vec{h}_i,\vec{\th}^{(t)}}\P{\vec{h}_i|\vec{\th}^{(t)}}}{\P{\vec{x}_i|\vec{\th}^{(t)}}} \\
	&=\frac{\Norm_{\vec{x}_i}[\vec{\mu}+\mat{\Ph}\vec{h}_i,\mat{\Si}]\Norm_{\vec{h}_i}[\vec{0},\mat{I}]}{\P{\vec{x}_i|\vec{\th}^{(t)}}} \\
	&=\Norm_{\vec{h_i}}\left[\left(\mat{\Ph}\TT\mat{\Si}\inv\mat{\Ph}+\mat{I}\right)\inv\mat{\Ph}\TT\mat{\Si}\inv(\vec{x}_i-\vec{\mu}),\mat{\Ph}\TT\mat{\Si}\inv\mat{\Ph}+\mat{I}\right]
\end{align*}
Extract expectations
\begin{align*}
	\E{\vec{h}_i}&=\left(\mat{\Ph}\TT\mat{\Si}\inv\mat{\Ph}+\mat{I}\right)\inv\mat{\Ph}\TT\mat{\Si}\inv(\vec{x}_i-\vec{\mu}) \\
	\E{\vec{h_i}\vec{h_i}\TT}&=\E{(\vec{h}_i-\E{\vec{h}_i})(\vec{h}_i-\E{\vec{h}_i})\TT}+\E{\vec{h}_i}\E{\vec{h}_i}\TT \\
	&=\left(\mat{\Ph}\TT\mat{\Si}\inv\mat{\Ph}+\mat{I}\right)\inv+\E{h_i}\E{h_i}\TT
\end{align*}
M-Step -- Maximize bound w.r.t. parameters $\vec{\th}$.
\begin{align*}
	\hat{\vec{\th}}^{(t+1)}&=\argmax_{\vec{\th}}\sum_{i=1}^N\int\hat{q}_i(\vec{h}_i)\log\P{\vec{x},\vec{h}_i|\vec{\th}}d\vec{h}_i \\
	&=\argmax_{\vec{\th}}\sum_{i=1}^N\int\hat{q}_i(\vec{h}_i)\left(\log\P{\vec{x}|\vec{h}_i,\vec{\th}}+\log\P{\vec{h}_i}\right)d\vec{h}_i \\
	&=\argmax_{\vec{\th}}\sum_{i=1}^N\int\hat{q}_i(\vec{h}_i)\log\P{\vec{x}|\vec{h}_i,\vec{\th}}d\vec{h}_i \\
	&=\argmax_{\vec{\th}}\sum_{i=1}^N\E{\P{\vec{x}|\vec{h}_i,\vec{\th}}}
\end{align*}
where
\begin{align*}
	\log\P{\vec{x}_i|\vec{h}_i}=-\frac{D\log 2\pi+\log\det{\mat{\Si}}+(\vec{x}_i-\vec{\mu}-\mat{\Ph}\vec{h}_i)\TT\mat{\Si}\inv(\vec{x}_i-\vec{\mu}-\mat{\Ph}\vec{h_i})}{2}
\end{align*}
The solutions are
\begin{align*}
	\hat{\vec{\mu}}&=\frac{\sum_{i=1}^N\vec{x}_i}{\mat{I}} \\
	\hat{\mat{\Ph}}&=\left(\sum_{i=1}^N(\vec{x}_i-\hat{\vec{\mu}})\E{\vec{h}_i}\TT\right)\left(\sum_{i=1}^N\E{\vec{h}_i\vec{h}_i\TT}\right)\inv \\
	\hat{\mat{\Si}}&=\frac{1}{\mat{I}}\sum_{i=1}diag\left[(\vec{x}_i-\hat{\vec{\mu}})\TT(\vec{x}_i-\hat{\vec{\mu}})-\hat{\mat{\Ph}}\E{\vec{h}_i}\vec{x}\TT\right]
\end{align*}



\section{Variational Inference}

\subsection{Markov Random Field}

Instead of dealing with the difficult distribution $p$ we are going to find the best approximation to it in a class of simpler distributions $q$. A canonical intractable distribution is Markov Random Field (MRF) that
\begin{align*}
	p(x)=\frac{1}{Z}e^{-E(x)}
\end{align*}
where $E(\bullet)$ is an energy function and on binary variables $x_i\in\{+1,-1\},i=1,\dots,D$ this may become $E(x)=-\sum_{i,j}w_{ij}x_ix_j-\sum_ib_ix_i$. Now we introduce a distribution $q$ and the KL divergence between $q$ and $p$ is
\begin{align*}
	\KL{q}{p}&=\vecx{\log q}_q-\vecx{\log p}_q \\
	&=-\H{q}-\vecx{-E(x)-\log Z}_q \\
	&=\vecx{E(x)}_q+\log Z-\H{q}\geq 0
\end{align*}
Rewriting, this gives a bound on the log-partition function
\begin{align*}
	\log Z\geq\vecx{-E(x)}_q+\H{q}
\end{align*}

\subsection{Mean Field Approximation}

A common approach to selecting a family of ``easy'' distribution $Q$ is to select a factorized distribution:
\begin{align*}
	Q(x)=\prod_{n=1}^Nq(x_n)
\end{align*}
This is a simplification and typically this family does not contain true distribution of interest. For a general intractable distribution $p(x)$ on discrete or continuous $x$, the KL divergence between a factorized approximation $q(x)=\prod_iq(x_i)$ and $p(x)$ is
\begin{align*}
	\KL{q(x)}{p(x)}=\sum_i\vecx{\log q(x_i)}_{q(x_i)}-\vecx{\log p(x)}_{\prod_iq(x_i)}
\end{align*}
Isolating the dependency of the above on a single factor $q(x_i)$ we have
\begin{align*}
	\vecx{\log q(x_i)}_{q(x_i)}-\vecx{\vecx{\log p(x)}_{\prod_{j\neq i}q(x_j)}}_{q(x_i)}
\end{align*}
Up to a normalization constant, this is therefore the KL divergence between $q(x_i)$ and a distribution proportional to $\e{\vecx{\log p(x)}_{\prod_{j\neq i}q(x_j)}}$ so that the optimal setting for $q(x_i)$ satisfies
\begin{align*}
	q(x_i)\prop\e{\vecx{\log p(x)}_{\prod_{j\neq i}q(x_j)}}
\end{align*}

\subsection{Variational Autoencoders}
