%!TEX root = ../notebook.tex
% Chapter 3

\chapter{Machine Learning Basics}
\label{chapter3}

\section{Regularization}

\subsection{Under-fitting \& Over-fitting}

\begin{description}[leftmargin=0cm]
\item[Under-fitting] If $N>D$ (e.g. 30 data points, 2 dimensions) we have more equations than unknowns: over-determined system. Input-output relations can only hold approximately.
\item[Over-fitting] If $N<D$ (e.g. 30points, 15265 dimensions) we have more unknowns than equations: under-determined system. Input-output equations hold exactly, but we are simply memorizing data.
\end{description}

\subsection{Bias \& Variance}

\begin{description}[leftmargin=0cm]
\item[High Bias \& Low Variance] A rigid model's (low complexity) performance is more predictable in the test set but the model may not be good even on the training set.
\item[Low Bias \& High Variance] A flexible model (high complexity) approximates the target function well in the training set but can ``overtrain'' and have poor performance on the test set.
\end{description}

\subsection{Vector Norm}

\begin{description}[leftmargin=0cm]
\item[L1, (``Manhattan'') norm] $\norm{\vec{w}}_1=\sum_{d=1}^D|w_d|$
\item[L2, (``Euclidean'') norm] $\norm{\vec{w}}_2=\sqrt{\sum_{d=1}^Dw_d^2}=\sqrt{\matmul{\vec{w},\vec{w}}}=\sqrt{\vec{w}\T\vec{w}}$
\item[Lp norm, p$>$1] $\norm{\vec{w}}_p=\left(\sum_{d=1}^Dw_d^p\right)^{1/p}$
\end{description}

\subsection{Penalize Complexity}

In linear regression, the residual vector is $\vec{\ep}=\vec{y}-\vec{\Ps}\vec{w}$. The loss function is $L(\vec{w})=\vec{\ep}\T\vec{\ep}$. We add a complexity term $R(\vec{w})=\norm{\vec{w}}_2=\vec{w}\T\vec{w}$ to the loss function. Hence, the original loss function becomes $L(\vec{w})=\vec{\ep}\T\vec{\ep}+\la\vec{w}\T\vec{w}$.

Without regularization, the loss function is $L(\vec{w})=\vec{\ep}\T\vec{\ep}$. Let $\grad L(\vec{w}^*)=0$, we have $\vec{w}^*=(\mat{X}\T\mat{X})\inv\mat{X}\T\vec{y}$.

With L2-regularization, the loss function is $L(\vec{w})=\vec{\ep}\T\vec{\ep}+\la\vec{w}\T\vec{w}$. Let $\grad L(\vec{w}^*)=0$, we have $\vec{w}^*=(\mat{X}\T\mat{X}+\la\mat{I})\inv\mat{X}\T\vec{y}$. The additional $\la\mat{I}$ makes the data matrix more robust to calculate inversion.

\section{Cross-Validation}

We can select hyperparameters with (cross-)validation. Cross-validation excludes part of the training data from parameter estimation, and use them only to predict the test error.

K-fold cross validation: split data set into K folds and each time train on (K-1) folds and valid on the remaining fold until all folds have been used as validation fold. The cross-validation error is the average of K validation errors. We pick hyperparameters that minimize cross-validation error.

\section{Bayesian Learning}

\subsection{Bayes' Rule Terminology}

Bayes' Rule:
	\begin{align*}
	\P{y|x}=\frac{\P{x|y}\P{y}}{\int\P{x|y}\P{y}dy}
	\end{align*}
\begin{description}[leftmargin=0cm]
	\item[Prior] $\P{y}$ what we know about $y$ before seeing $x$. In parameters learning we choose prior that is conjugate to likelihood.
	\item[Likelihood] $\P{x|y}$ propensity for observing a certain value of $x$ given a certain value of $y$.
	\item[Posterior] $\P{y|x}$ what we know about $y$ after seeing $x$. Posterior must have same form as conjugate prior distribution.
	\item[Evidence] $\int\P{x|y}\P{y}dy$ a constant to ensure that the LHS is a valid distribution. Posterior must be a distribution which implies that evidence equals to a constant $\ka$ from conjugate relation.
\end{description}

\subsection{Maximum Likelihood}

\begin{description}[leftmargin=0cm]
\item[Fitting] As the name suggests we find the parameters under which the data $\vec{x}_{1\dots I}$ are most likely. Here, we have assumed that data was independent.
	\begin{align*}
	\hat{\vec{\th}}&=\argmax_{\vec{\th}}\P{\vec{x}_{1\dots I}|\vec{\th}} \\
	&=\argmax_{\vec{\th}}\prod_{i=1}^I\P{\vec{x}_i|\vec{\th}}
	\end{align*}
\item[Predictive Density] Evaluate new data point $\vec{x}^*$ under probability distribution $\P{\vec{x}^*|\hat{\vec{\th}}}$ with best parameters.
\end{description}

\subsection{Maximum a Posterior (MAP)}

\begin{description}[leftmargin=0cm]
\item[Fitting] As the name suggests we find the parameters which maximize the posterior probability $\P{\vec{\th}|\vec{x}_{1\dots I}}$. Again we have assumed that data was independent.
	\begin{align*}
	\hat{\vec{\th}}&=\argmax_{\vec{\th}}\P{\vec{\th}|\vec{x}_{1\dots I}} \\
	&=\argmax_{\vec{\th}}\frac{\P{\vec{x}_{1\dots I}|\vec{\th}}\P{\vec{\th}}}{\P{\vec{x}_{1\dots I}}} \\
	&=\argmax_{\vec{\th}}\frac{\prod_{i=1}^I\P{\vec{x}_i|\vec{\th}}\ \P{\vec{\th}}}{\P{\vec{x}_{1\dots I}}}
	\end{align*}
Since the denominator does not depend on the parameters we can instead maximize
	\begin{align*}
	\hat{\vec{\th}}=\argmax_{\vec{\th}}\prod_{i=1}^I\P{\vec{x}_i|\vec{\th}}\ \P{\vec{\th}}
	\end{align*}
\item[Predictive Density] Evaluate new data point $\vec{x}^*$ under probability distribution with MAP parameters $\P{\vec{x}^*|\hat{\vec{\th}}}$
\end{description}

\subsection{Bayesian Approach}

\begin{description}[leftmargin=0cm]
\item[Fitting] Compute the posterior distribution over possible parameter values using Bayes' rule. Principle: There are many values that could have explained the data. Instead of picking one set of parameters, try to capture all of the possibilities.
	\begin{align*}
	\P{\vec{\th}|\vec{x}_{1\dots I}}=\frac{\prod_{i=1}^I\P{\vec{x}_i|\vec{\th}}\ \P{\vec{\th}}}{\P{\vec{x}_{1\dots I}}}
	\end{align*}
\item[Predictive Density] (a) Each possible parameter value makes a prediction. (b) Some parameters more probable than others.
	\begin{align*}
	\P{\vec{x}^*|\vec{x}_{1\dots I}}=\int\P{\vec{x}^*|\vec{\th}}\P{\vec{\th}|\vec{x}_{1\dots I}}d\vec{\th}
	\end{align*}
Make a prediction that is an infinite weighted sum (integral) of the predictions for each parameter value ($\P{\vec{x}^*|\vec{\th}}$), where weights are the probabilities ($\P{\vec{\th}|\vec{x}_{1\dots I}}$).
\end{description}

\subsection{Example: Univariate Normal Distribution}

\subsubsection*{Maximum Likelihood}
Likelihood given by normal distribution pdf:
	\begin{align*}
	\P{x|\mu,\si^2}=\Norm_x[\mu,\si^2]=\frac{1}{\sqrt{2\pi\si^2}}\e{-\frac{(x-\mu)^2}{2\si^2}}
	\end{align*}
Apply maximum likelihood:
	\begin{align*}
	\hat{\mu},\hat{\si}^2&=\argmax_{\mu,\si^2}\P{x_{1\dots I}|\mu,\si^2} \\
	&=\argmax_{\mu,\si^2}\prod_{i=1}^I\P{x_i|\mu,\si^2} \\
	&=\argmax_{\mu,\si^2}\prod_{i=1}^I\Norm_{x_i}[\mu,\si^2] \\
	&=\argmax_{\mu,\si^2}\sum_{i=1}^I\log\Norm_{x_i}[\mu,\si^2] \\
	&=\argmax_{\mu,\si^2}\left(-\frac{I}{2}\log 2\pi-\frac{I}{2}\log\si^2-\frac{1}{2}\sum_{i=1}^I\frac{(x_i-\mu)^2}{\si^2}\right)
	\end{align*}
Let $\grad L(\hat{\mu},\hat{\si}^2)=0$, we have the solution:
	\begin{align*}
	\hat{\mu}&=\frac{\sum_{i=1}^Ix_i}{I} \\
	\hat{\si}^2&=\sum_{i=1}^I\frac{(x_i-\hat{\mu})^2}{I}
	\end{align*}

\subsubsection*{Maximum a Posterior}
Likelihood given by normal distribution pdf:
	\begin{align*}
	\P{x|\mu,\si^2}=\Norm_x[\mu,\si^2]=\frac{1}{\sqrt{2\pi\si^2}}\e{-\frac{(x-\mu)^2}{2\si^2}}
	\end{align*}
Prior given by normal inverse gamma distribution pdf:
	\begin{align*}
	\P{\mu,\si^2}=\NIG_{\mu,\si^2}[\al,\be,\ga,\de]=\frac{\sqrt{\ga}}{\sqrt{2\pi\si^2}}\frac{\be^\al}{\Ga(\al)}\left(\frac{1}{\si^2}\right)^{\al+1}\e{-\frac{2\be+\ga(\de-\mu)^2}{2\si^2}}
	\end{align*}
Apply maximum a posterior:
	\begin{align*}
	\hat{\mu},\hat{\si}^2&=\argmax_{\mu,\si^2}\prod_{i=1}^I\P{x_i|\mu,\si^2}\ \P{\mu,\si^2} \\
	&=\argmax_{\mu,\si^2}\prod_{i=1}^I\Norm_{x_i}[\mu,\si^2]\ \NIG_{\mu,\si^2}[\al,\be,\ga,\de] \\
	&=\argmax_{\mu,\si^2}\left(\sum_{i=1}^I\log\Norm_{x_i}[\mu,\si^2]+\log\NIG_{\mu,\si^2}[\al,\be,\ga,\de]\right)
	\end{align*}
Let $\grad L(\hat{\mu},\hat{\si}^2)=0$, we have the solution:
	\begin{align*}
	\hat{\mu}&=\frac{\sum_{i=1}^Ix_i+\ga\de}{I+\ga} \\
	\hat{\si}^2&=\frac{\sum_{i=1}^I(x_i-\mu)^2+2\be+\ga(\de-\mu)^2}{I+3+2\al}
	\end{align*}

\subsubsection*{Bayesian Approach}
Compute the posterior distribution using Bayes' rule:
	\begin{align*}
	\P{\mu,\si^2|x_{1\dots I}}&=\frac{\prod_{i=1}^I\P{x_i|\mu,\si^2}\ \P{\mu,\si^2}}{\P{x_{1\dots I}}} \\
	&=\frac{\prod_{i=1}^I\Norm_{x_i}[\mu,\si^2]\ \NIG_{\mu,\si^2}[\al,\be,\ga,\de]}{\P{x_{1\dots I}}} \\
	&=\frac{\ka(\al,\be,\ga,\de,x_{1\dots I})\NIG_{\mu,\si^2}[\ti{\al},\ti{\be},\ti{\ga},\ti{\de}]}{\P{x_{1\dots I}}} \\
	&=\NIG_{\mu,\si^2}[\ti{\al},\ti{\be},\ti{\ga},\ti{\de}]
	\end{align*}
where
	\begin{align*}
	\ti{\al}&=\al+\frac{I}{2} \\
	\ti{\be}&=\frac{\sum_ix_i^2}{2}+\be+\frac{\ga\de^2}{2}-\frac{(\ga\de+\sum_ix_i)^2}{2(\ga+I)} \\
	\ti{\ga}&=\ga+I \\
	\ti{\de}&=\frac{\ga\de+\sum_ix_i}{\ga+I}
	\end{align*}
Take weighted sum of predictions from different parameter values:
	\begin{align*}
	\P{x^*|x_{1\dots I}}&=\iint\P{x^*|\mu,\si^2}\P{\mu,\si^2|x_{1\dots I}}d\mu d\si \\
	&=\iint\Norm_{x^*}[\mu,\si^2]\NIG_{\mu,\si^2}[\ti{\al},\ti{\be},\ti{\ga},\ti{\de}]d\mu d\si \\
	&=\iint\ka(\al,\be,\ga,\de,x_{1\dots I})\NIG_{\mu,\si^2}[\br{\al},\br{\be},\br{\ga},\br{\de}]d\mu d\si \\
	&=\ka(\al,\be,\ga,\de,x_{1\dots I})\iint\NIG_{\mu,\si^2}[\br{\al},\br{\be},\br{\ga},\br{\de}]d\mu d\si \\
	&=\ka(\al,\be,\ga,\de,x_{1\dots I}) \\
	&=\frac{1}{\sqrt{2\pi}}\frac{\sqrt{\ti{\ga}}\ti{\be}^{\ti{\al}}}{\sqrt{\br{\ga}}\br{\be}^{\br{\al}}}\frac{\Ga(\br{\al})}{\Ga(\ti{\al})}
	\end{align*}
where
	\begin{align*}
	\br{\al}&=\ti{\al}+\frac{1}{2} \\
	\br{\be}&=\frac{{x^*}^2}{2}+\ti{\be}+\frac{\ti{\ga}^{\ti{\de}^2}}{2}-\frac{(\ti{\ga}^{\ti{\de}}+x^*)^2}{2(\ti{\ga}+1)} \\
	\br{\ga}&=\ti{\ga}+1
	\end{align*}

\subsection{Example: Categorical Distribution}

\subsubsection*{Maximum Likelihood}
Likelihood given by categorical distribution pdf:
	\begin{align*}
	\P{x|\vec{\la}}=\Cat_x[\vec{\la}]=\prod_{j=1}^K\la_j^{x_j}=\la_k
	\end{align*}
Apply maximum likelihood:
	\begin{align*}
	\hat{\vec{\la}}&=\argmax_{\vec{\la}}\prod_{i=1}^I\P{x_i|\vec{\la}} && \text{$s.t. \sum_k\la_k=1$} \\
	&=\argmax_{\vec{\la}}\prod_{i=1}^I\Cat_{x_i}[\vec{\la}] && \text{$s.t. \sum_k\la_k=1$} \\
	&=\argmax_{\vec{\la}}\prod_{k=1}^K\la_k^{N_k} && \text{$s.t. \sum_k\la_k=1$} \\
	&=\argmax_{\vec{\la}}\sum_{k=1}^KN_k\log\la_k && \text{$s.t. \sum_k\la_k=1$}
	\end{align*}
Here, $N_k$ represents the number of times the data is classified in class $k$. As before, we will instead optimize log probability. Since there is a constraint $s.t. \sum_k\la_k=1$, we use Lagrange multiplier to reconstruct the loss function.
	\begin{align*}
	L(\vec{\la})=\sum_{k=1}^KN_k\log\la_k+v\left(\sum_{k=1}^K\la_k-1\right)
	\end{align*}
Let $\grad L(\vec{\la},v)=0$, we have the solution:
	\begin{align*}
	\hat{\la}_k=\frac{N_k}{\sum_{m=1}^KN_m}
	\end{align*}

\subsubsection*{Maximum a Posterior}
Likelihood given by categorical distribution pdf:
	\begin{align*}
	\P{x|\vec{\la}}=\Cat_x[\vec{\la}]=\prod_{j=1}^K\la_j^{x_j}=\la_k
	\end{align*}
Prior given by Dirichlet distribution pdf:
	\begin{align*}
	\P{\vec{\la}}=\Dir_{\vec{\la}}[\vec{\al}]=\frac{\Ga(\sum_{k=1}^K\al_k)}{\prod_{k=1}^K\Ga(\al_k)}\prod_{k=1}^K\la_k^{\al_k-1}
	\end{align*}
Apply maximum a posterior:
	\begin{align*}
	\hat{\vec{\la}}&=\argmax_{\vec{\la}}\prod_{i=1}^I\P{x_i|\vec{\la}}\ \P{\vec{\la}} && \text{$s.t. \sum_k\la_k=1$} \\
	&=\argmax_{\vec{\la}}\Cat_{x_i}[\vec{\la}]\ \Dir_{\vec{\la}}[\vec{\al}] && \text{$s.t. \sum_k\la_k=1$} \\
	&=\argmax_{\vec{\la}}\prod_{k=1}^K\la_k^{N_k}\prod_{k=1}^K\la_k^{\al_k-1} && \text{$s.t. \sum_k\la_k=1$} \\
	&=\argmax_{\vec{\la}}\prod_{k=1}^K\la_k^{N_k+\al_k-1} && \text{$s.t. \sum_k\la_k=1$} \\
	&=\argmax_{\vec{\la}}\sum_{k=1}^K(N_k+\al_k-1)\log\la_k && \text{$s.t. \sum_k\la_k=1$}
	\end{align*}
The loss function is very similar to maximum likelihood (same when the prior is uniform, i.e. $\al_{1\dots k}=1$). Take derivative with Lagrange multiplier, we have the solution:
	\begin{align*}
	\hat{\la}_k=\frac{N_k+\al_k-1}{\sum_{m=1}^K(N_m+\al_m-1)}
	\end{align*}

\subsubsection*{Bayesian Approach}
Compute the posterior distribution using Bayes' rule:
	\begin{align*}
	\P{\vec{\la}|x_{1\dots I}}&=\frac{\prod_{i=1}^I\P{x_i|\vec{\la}}\ \P{\vec{\la}}}{\P{x_{1\dots I}}} \\
	&=\frac{\prod_{i=1}^I\Cat_{x_i}[\vec{\la}]\ \Dir_{\vec{\la}}[\vec{\al}]}{\P{x_{1\dots I}}} \\
	&=\frac{\ka(\vec{\al},x_{1\dots I})\Dir_{\vec{\la}}[\ti{\vec{\al}}]}{\P{x_{1\dots I}}} \\
	&=\Dir_{\vec{\la}}[\ti{\vec{\al}}]
	\end{align*}
Compute predictive distribution:
	\begin{align*}
	\P{x^*|x_{1\dots I}}&=\int\P{x^*|\vec{\la}}\P{\vec{\la}|x_{1\dots I}}d\vec{\la} \\
	&=\int\Cat_{x^*}[\vec{\la}]\Dir_{\vec{\la}}[\ti{\vec{\al}}]d\vec{\la} \\
	&=\int\ka(x^*,\ti{\vec{\al}})\Dir_{\vec{\la}}[\br{\vec{\al}}]d\vec{\la} \\
	&=\ka(x^*,\vec{\al})
	\end{align*}

\section{Machine Learning Models}

\subsection{Learning and Inference}

In real world problems, we usually have two tasks:
	\begin{enumerate}
		\item Observe measured data, \textbf{x}
		\item Draw inferences from it about world, \textbf{w}
	\end{enumerate}
and
	\begin{enumerate}
		\item When the world state \textbf{w} is \textit{continuous}, we'll call this \textit{regression}.
		\item When the world state \textbf{w} is \textit{discrete}, we'll call this \textit{classification}.
	\end{enumerate}
We want take observations \textbf{x}, and return probability distribution $\P{\bf w|x}$ over possible worlds compatible with data. To solve this, we need
	\begin{enumerate}
		\item A \textit{model} that mathematically relates the visual data \textbf{x} to the world state \textbf{w}. Model specifies family of relationships, particular relationship depends on parameter ${\bf \th}$.
		\item A \textit{learning algorithm} fits parameters ${\bf \th}$ from paired training examples ${\bf x_i}$, ${\bf w_i}$.
		\item An \textit{inference algorithm} uses model to return $\P{\bf w|x}$ given new observation data \textbf{x}.
	\end{enumerate}

\subsection{Three Types of Model}

We have three types of model:
	\begin{enumerate}
		\item Model contingency of the world on the data $\P{w|x}$. (Discriminative Model)
		\item Model joint occurrence of world and data $\P{x,w}$. (Generative Model)
		\item Model contingency of data on world $\P{x|w}$. (Generative Model)
	\end{enumerate}
Within the three models, type 1 is called \textit{Discriminative Model}. Type 2 and 3 are called \textit{Generative Model}.

\subsubsection*{Model $\P{w|x}$ - Discriminative}
	\begin{enumerate}
		\item $\P{w|x,\th}=\Dis_w[f(x,\th)]$
		\item How to model: (a) Choose an appropriate form for $\P{w}$. (b) Make parameters a function of $x$. (c) Function takes parameters $\th$ that define its shape.
		\item Learning algorithm: Learn parameters $\th$ from training data $x$, $w$.
		\item Inference algorithm: Just evaluate $\P{w|x}$
	\end{enumerate}

\subsubsection*{Model $\P{x,w}$ - Generative}
	\begin{enumerate}
		\item $\P{z|\th}=\Dis_z[\th]$
		\item How to model: (a) Concatenate $x$ and $w$ to make $z=[x\T,w\T]\T$. (b) Model the pdf of $z$. (c) pdf takes parameters $\th$ that define its shape.
		\item Learning algorithm: Learn parameters $\th$ from training data $x$, $w$.
		\item Inference algorithm: Compute $\P{w|x}$ using Bayes' rule $\P{w|x}=\frac{\P{x,w}}{\P{x}}=\frac{\P{x,w}}{\int\P{x,w}dw}$.
	\end{enumerate}

\subsubsection*{Model $\P{x|w}$ - Generative}
	\begin{enumerate}
		\item $\P{x|w,\th}=\Dis_x[f(w,\th)]$
		\item How to model: (a) Choose an appropriate form for $\P{x}$. (b) Make parameters a function of $w$. (c) Function takes parameters $\th$ that define its shape.
		\item Learning algorithm: Learn parameters $\th$ from training data $x$, $w$.
		\item Define prior $\P{w}$ and then compute $\P{w|x}$ using Bayes' rule $\P{w|x}=\frac{\P{x|w}\P{w}}{\int\P{x|w}\P{w}dw}$.
	\end{enumerate}

\subsection{Example: Regression}

Consider a simple case:
	\begin{enumerate}
		\item We make a univariate continuous measurement $x$.
		\item Use this to predict a univariate continuous state $w$.
	\end{enumerate}

\subsubsection*{Model $\P{w|x}$ - Discriminative}
	\begin{enumerate}
		\item $\P{w|x,\vec{\th}}=\Norm_w[\ph_0+\ph_1x,\si^2], \vec{\th}=\{\ph_0,\ph_1,\si^2\}$
		\item How to model: (a) Choose normal distribution over $w$. (b) Make mean $\mu$ linear function of $x$ (variance constant). (c) Parameters are $\ph_0$ (y-offset), $\ph_1$ (slope), $\si^2$ (variance). This model is called \textit{linear regression}.
		\item Learning algorithm: Learn $\vec{\th}$ from training data $x$, $w$. e.g. MAP:
		\begin{align*}
		\hat{\vec{\th}}&=\argmax_{\vec{\th}}\P{\vec{\th}|w_{1\dots I},x_{1\dots I}} \\
		&=\argmax_{\vec{\th}}\P{w_{1\dots I}|x_{1\dots I},\vec{\th}}\P{\vec{\th}} \\
		&=\argmax_{\vec{\th}}\prod_{i=1}^I\P{w_i|x_i,\vec{\th}}\P{\vec{\th}}
		\end{align*}
		\item Inference algorithm:Just evaluate $\P{w|x}$ for new data $x$.
	\end{enumerate}

\subsubsection*{Model $\P{x,w}$ - Generative}
	\begin{enumerate}
		\item $\P{x,w|\vec{\th}}=\Norm_{x,w}[\vec{\mu},\cov], \vec{\th}=\{\vec{\mu},\cov\}$
		\item How to model: (a) Concatenate $x$ and $w$ to make $z=[x\T,w\T]\T$. (b) Model the pdf of $z$ as normal distribution. (c) pdf makes parameters $\vec{\mu}$ and $\cov$ that define its shape.
		\item Learning algorithm: Learn parameters $\th$ from training data $x$, $w$.
		\item Inference algorithm: Compute $\P{w|x}$ using Bayes' rule $\P{w|x}=\frac{\P{x,w}}{\P{x}}=\frac{\P{x,w}}{\int\P{x,w}dw}$.
	\end{enumerate}

\subsubsection*{Model $\P{x|w}$ - Generative}
	\begin{enumerate}
		\item $\P{x|w,\vec{\th}}=\Norm_x[\ph_0+\ph_1w,\si^2], \vec{\th}=\{\ph_0,\ph_1,\si^2\}$
		\item How to model: (a) Choose normal distribution over $x$. (b) Make mean $\mu$ linear function of $w$ (variance constant). (c) Parameters are $\ph_0$, $\ph_1$, $\si^2$.
		\item Learning algorithm: Learn $\vec{\th}$ from training data $x$, $w$. e.g. MAP
		\item Inference algorithm: Compute $\P{w|x}$ using Bayes' rule $\P{w|x}=\frac{\P{x,w}}{\P{x}}=\frac{\P{x,w}}{\int\P{x,w}dw}$.
	\end{enumerate}

\subsection{Example: Classification}

Consider a simple case:
	\begin{enumerate}
		\item We make a univariate continuous measurement $x$.
		\item Use this to predict a discrete binary world $w \in \{0,1\}$.
	\end{enumerate}

\subsubsection*{Model $\P{w|x}$ - Discriminative}
	\begin{enumerate}
		\item $\P{w|x,\vec{\th}}=\Bern_w[\sig{\ph_0+\ph_1x}], \vec{\th}={\ph_0,\ph_1}$
		\item How to model: (a) Choose Bernoulli distribution for $\P{w}$. (b) Make parameters a sigmoid-activated function of $x$. (c) Function takes parameters $\ph_0$ and $\ph_1$. This model is called \textit{logistic regression}.
		\item Learning algorithm: Learning by standard methods, e.g. ML, MAP, Bayesian Approach.
		\item Inference algorithm: Just evaluate $\P{w|x}$.
	\end{enumerate}

\subsubsection*{Model $\P{x,w}$ - Generative}
Can't build this mode very easily:
	\begin{enumerate}
		\item Concatenate continuous vector $x$ and discrete $w$ to make $z$.
		\item No obvious probability distribution to model joint probability of discrete and continuous.
	\end{enumerate}

\subsubsection*{Model $\P{x|w}$ - Generative}
	\begin{enumerate}
		\item $\P{x|w,\vec{\th}}=\Norm_x[\mu_w,\si_w^2], \vec{\th}=\{\mu_0,\mu_1,\si_0^2,\si_1^2\}$
		\item How to model: (a) Choose a Normal distribution for $\P{x}$. (b) Make parameters a function of discrete binary $w$. (c) Function takes parameters $\mu_0$, $\mu_1$, $\si_0^2$, $\si_1^2$ that define its shape. 
		\item Learning algorithm: Learning by standard methods, e.g. ML, MAP, Bayesian Approach.
		\item Define prior $\P{w}$ and then compute $\P{w|x}$ using Bayes' rule $\P{w|x}=\frac{\P{x|w}\P{w}}{\int\P{x|w}\P{w}dw}$.
	\end{enumerate}