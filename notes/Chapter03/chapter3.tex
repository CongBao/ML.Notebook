%!TEX root = ../notebook.tex
% Chapter 3

\chapter{Machine Learning Basics}
\label{chapter3}

\section{Regularization}

\subsection{Under-fitting \& Over-fitting}

\begin{description}[leftmargin=0cm]
\item[Under-fitting] If $N>D$ (e.g. 30 data points, 2 dimensions) we have more equations than unknowns: over-determined system. Input-output relations can only hold approximately.
\item[Over-fitting] If $N<D$ (e.g. 30points, 15265 dimensions) we have more unknowns than equations: under-determined system. Input-output equations hold exactly, but we are simply memorizing data.
\end{description}

\subsection{Bias \& Variance}

\begin{description}[leftmargin=0cm]
\item[High Bias \& Low Variance] A rigid model's (low complexity) performance is more predictable in the test set but the model may not be good even on the training set.
\item[Low Bias \& High Variance] A flexible model (high complexity) approximates the target function well in the training set but can ``overtrain'' and have poor performance on the test set.
\end{description}

\subsection{Vector Norm}

\begin{description}[leftmargin=0cm]
\item[L1, (``Manhattan'') norm] $\norm{\vec{w}}_1=\sum_{d=1}^D|w_d|$
\item[L2, (``Euclidean'') norm] $\norm{\vec{w}}_2=\sqrt{\sum_{d=1}^Dw_d^2}=\sqrt{\matmul{\vec{w},\vec{w}}}=\sqrt{\vec{w}\T\vec{w}}$
\item[Lp norm, p$>$1] $\norm{\vec{w}}_p=\left(\sum_{d=1}^Dw_d^p\right)^{1/p}$
\end{description}

\subsection{Penalize Complexity}

In linear regression, the residual vector is $\vec{\ep}=\vec{y}-\vec{\Ps}\vec{w}$. The loss function is $L(\vec{w})=\vec{\ep}\T\vec{\ep}$. We add a complexity term $R(\vec{w})=\norm{\vec{w}}_2=\vec{w}\T\vec{w}$ to the loss function. Hence, the original loss function becomes $L(\vec{w})=\vec{\ep}\T\vec{\ep}+\la\vec{w}\T\vec{w}$.

Without regularization, the loss function is $L(\vec{w})=\vec{\ep}\T\vec{\ep}$. Let $\grad L(\vec{w}^*)=0$, we have $\vec{w}^*=(\mat{X}\T\mat{X})\inv\mat{X}\T\vec{y}$.

With L2-regularization, the loss function is $L(\vec{w})=\vec{\ep}\T\vec{\ep}+\la\vec{w}\T\vec{w}$. Let $\grad L(\vec{w}^*)=0$, we have $\vec{w}^*=(\mat{X}\T\mat{X}+\la\mat{I})\inv\mat{X}\T\vec{y}$. The additional $\la\mat{I}$ makes the data matrix more robust to calculate inversion.

\section{Cross-Validation}

We can select hyperparameters with (cross-)validation. Cross-validation excludes part of the training data from parameter estimation, and use them only to predict the test error.

K-fold cross validation: split data set into K folds and each time train on (K-1) folds and valid on the remaining fold until all folds have been used as validation fold. The cross-validation error is the average of K validation errors. We pick hyperparameters that minimize cross-validation error.

\section{Bayesian Learning}

\subsection{Bayes' Rule Terminology}

Bayes' Rule:
	\begin{align*}
	\P{y|x}=\frac{\P{x|y}\P{y}}{\int\P{x|y}\P{y}dy}
	\end{align*}
\begin{description}[leftmargin=0cm]
	\item[Prior] $\P{y}$ what we know about $y$ before seeing $x$. In parameters learning we choose prior that is conjugate to likelihood.
	\item[Likelihood] $\P{x|y}$ propensity for observing a certain value of $x$ given a certain value of $y$.
	\item[Posterior] $\P{y|x}$ what we know about $y$ after seeing $x$. Posterior must have same form as conjugate prior distribution.
	\item[Evidence] $\int\P{x|y}\P{y}dy$ a constant to ensure that the LHS is a valid distribution. Posterior must be a distribution which implies that evidence equals to a constant $\ka$ from conjugate relation.
\end{description}

\subsection{Maximum Likelihood}

\begin{description}[leftmargin=0cm]
\item[Fitting] As the name suggests we find the parameters under which the data $\vec{x}_{1\dots I}$ are most likely. Here, we have assumed that data was independent.
	\begin{align*}
	\hat{\vec{\th}}&=\argmax_{\vec{\th}}\P{\vec{x}_{1\dots I}|\vec{\th}} \\
	&=\argmax_{\vec{\th}}\prod_{i=1}^I\P{\vec{x}_i|\vec{\th}}
	\end{align*}
\item[Predictive Density] Evaluate new data point $\vec{x}^*$ under probability distribution $\P{\vec{x}^*|\hat{\vec{\th}}}$ with best parameters.
\end{description}

\subsection{Maximum a Posterior (MAP)}

\begin{description}[leftmargin=0cm]
\item[Fitting] As the name suggests we find the parameters which maximize the posterior probability $\P{\vec{\th}|\vec{x}_{1\dots I}}$. Again we have assumed that data was independent.
	\begin{align*}
	\hat{\vec{\th}}&=\argmax_{\vec{\th}}\P{\vec{\th}|\vec{x}_{1\dots I}} \\
	&=\argmax_{\vec{\th}}\frac{\P{\vec{x}_{1\dots I}|\vec{\th}}\P{\vec{\th}}}{\P{\vec{x}_{1\dots I}}} \\
	&=\argmax_{\vec{\th}}\frac{\prod_{i=1}^I\P{\vec{x}_i|\vec{\th}}\ \P{\vec{\th}}}{\P{\vec{x}_{1\dots I}}}
	\end{align*}
Since the denominator does not depend on the parameters we can instead maximize
	\begin{align*}
	\hat{\vec{\th}}=\argmax_{\vec{\th}}\prod_{i=1}^I\P{\vec{x}_i|\vec{\th}}\ \P{\vec{\th}}
	\end{align*}
\item[Predictive Density] Evaluate new data point $\vec{x}^*$ under probability distribution with MAP parameters $\P{\vec{x}^*|\hat{\vec{\th}}}$
\end{description}

\subsection{Bayesian Approach}

\begin{description}[leftmargin=0cm]
\item[Fitting] Compute the posterior distribution over possible parameter values using Bayes' rule. Principle: There are many values that could have explained the data. Instead of picking one set of parameters, try to capture all of the possibilities.
	\begin{align*}
	\P{\vec{\th}|\vec{x}_{1\dots I}}=\frac{\prod_{i=1}^I\P{\vec{x}_i|\vec{\th}}\ \P{\vec{\th}}}{\P{\vec{x}_{1\dots I}}}
	\end{align*}
\item[Predictive Density] (a) Each possible parameter value makes a prediction. (b) Some parameters more probable than others.
	\begin{align*}
	\P{\vec{x}^*|\vec{x}_{1\dots I}}=\int\P{\vec{x}^*|\vec{\th}}\P{\vec{\th}|\vec{x}_{1\dots I}}d\vec{\th}
	\end{align*}
Make a prediction that is an infinite weighted sum (integral) of the predictions for each parameter value ($\P{\vec{x}^*|\vec{\th}}$), where weights are the probabilities ($\P{\vec{\th}|\vec{x}_{1\dots I}}$).
\end{description}

\subsection{Example: Univariate Normal Distribution}

\subsubsection*{Maximum Likelihood}
Likelihood given by normal distribution pdf:
	\begin{align*}
	\P{x|\mu,\si^2}=\Norm_x[\mu,\si^2]=\frac{1}{\sqrt{2\pi\si^2}}\e{-\frac{(x-\mu)^2}{2\si^2}}
	\end{align*}
Apply maximum likelihood:
	\begin{align*}
	\hat{\mu},\hat{\si}^2&=\argmax_{\mu,\si^2}\P{x_{1\dots I}|\mu,\si^2} \\
	&=\argmax_{\mu,\si^2}\prod_{i=1}^I\P{x_i|\mu,\si^2} \\
	&=\argmax_{\mu,\si^2}\prod_{i=1}^I\Norm_{x_i}[\mu,\si^2] \\
	&=\argmax_{\mu,\si^2}\sum_{i=1}^I\log\Norm_{x_i}[\mu,\si^2] \\
	&=\argmax_{\mu,\si^2}\left(-\frac{I}{2}\log 2\pi-\frac{I}{2}\log\si^2-\frac{1}{2}\sum_{i=1}^I\frac{(x_i-\mu)^2}{\si^2}\right)
	\end{align*}
Let $\grad L(\hat{\mu},\hat{\si}^2)=0$, we have the solution:
	\begin{align*}
	\hat{\mu}&=\frac{\sum_{i=1}^Ix_i}{I} \\
	\hat{\si}^2&=\sum_{i=1}^I\frac{(x_i-\hat{\mu})^2}{I}
	\end{align*}

\subsubsection*{Maximum a Posterior}
Likelihood given by normal distribution pdf:
	\begin{align*}
	\P{x|\mu,\si^2}=\Norm_x[\mu,\si^2]=\frac{1}{\sqrt{2\pi\si^2}}\e{-\frac{(x-\mu)^2}{2\si^2}}
	\end{align*}
Prior given by normal inverse gamma distribution pdf:
	\begin{align*}
	\P{\mu,\si^2}=\NIG_{\mu,\si^2}[\al,\be,\ga,\de]=\frac{\sqrt{\ga}}{\sqrt{2\pi\si^2}}\frac{\be^\al}{\Ga(\al)}\left(\frac{1}{\si^2}\right)^{\al+1}\e{-\frac{2\be+\ga(\de-\mu)^2}{2\si^2}}
	\end{align*}
Apply maximum a posterior:
	\begin{align*}
	\hat{\mu},\hat{\si}^2&=\argmax_{\mu,\si^2}\prod_{i=1}^I\P{x_i|\mu,\si^2}\ \P{\mu,\si^2} \\
	&=\argmax_{\mu,\si^2}\prod_{i=1}^I\Norm_{x_i}[\mu,\si^2]\ \NIG_{\mu,\si^2}[\al,\be,\ga,\de] \\
	&=\argmax_{\mu,\si^2}\left(\sum_{i=1}^I\log\Norm_{x_i}[\mu,\si^2]+\log\NIG_{\mu,\si^2}[\al,\be,\ga,\de]\right)
	\end{align*}
Let $\grad L(\hat{\mu},\hat{\si}^2)=0$, we have the solution:
	\begin{align*}
	\hat{\mu}&=\frac{\sum_{i=1}^Ix_i+\ga\de}{I+\ga} \\
	\hat{\si}^2&=\frac{\sum_{i=1}^I(x_i-\mu)^2+2\be+\ga(\de-\mu)^2}{I+3+2\al}
	\end{align*}

\subsubsection*{Bayesian Approach}
Compute the posterior distribution using Bayes' rule:
	\begin{align*}
	\P{\mu,\si^2|x_{1\dots I}}&=\frac{\prod_{i=1}^I\P{x_i|\mu,\si^2}\ \P{\mu,\si^2}}{\P{x_{1\dots I}}} \\
	&=\frac{\prod_{i=1}^I\Norm_{x_i}[\mu,\si^2]\ \NIG_{\mu,\si^2}[\al,\be,\ga,\de]}{\P{x_{1\dots I}}} \\
	&=\frac{\ka(\al,\be,\ga,\de,x_{1\dots I})\NIG_{\mu,\si^2}[\ti{\al},\ti{\be},\ti{\ga},\ti{\de}]}{\P{x_{1\dots I}}} \\
	&=\NIG_{\mu,\si^2}[\ti{\al},\ti{\be},\ti{\ga},\ti{\de}]
	\end{align*}
where
	\begin{align*}
	\ti{\al}&=\al+\frac{I}{2} \\
	\ti{\be}&=\frac{\sum_ix_i^2}{2}+\be+\frac{\ga\de^2}{2}-\frac{(\ga\de+\sum_ix_i)^2}{2(\ga+I)} \\
	\ti{\ga}&=\ga+I \\
	\ti{\de}&=\frac{\ga\de+\sum_ix_i}{\ga+I}
	\end{align*}
Take weighted sum of predictions from different parameter values:
	\begin{align*}
	\P{x^*|x_{1\dots I}}&=\iint\P{x^*|\mu,\si^2}\P{\mu,\si^2|x_{1\dots I}}d\mu d\si \\
	&=\iint\Norm_{x^*}[\mu,\si^2]\NIG_{\mu,\si^2}[\ti{\al},\ti{\be},\ti{\ga},\ti{\de}]d\mu d\si \\
	&=\iint\ka(\al,\be,\ga,\de,x_{1\dots I})\NIG_{\mu,\si^2}[\br{\al},\br{\be},\br{\ga},\br{\de}]d\mu d\si \\
	&=\ka(\al,\be,\ga,\de,x_{1\dots I})\iint\NIG_{\mu,\si^2}[\br{\al},\br{\be},\br{\ga},\br{\de}]d\mu d\si \\
	&=\ka(\al,\be,\ga,\de,x_{1\dots I}) \\
	&=\frac{1}{\sqrt{2\pi}}\frac{\sqrt{\ti{\ga}}\ti{\be}^{\ti{\al}}}{\sqrt{\br{\ga}}\br{\be}^{\br{\al}}}\frac{\Ga(\br{\al})}{\Ga(\ti{\al})}
	\end{align*}
where
	\begin{align*}
	\br{\al}&=\ti{\al}+\frac{1}{2} \\
	\br{\be}&=\frac{{x^*}^2}{2}+\ti{\be}+\frac{\ti{\ga}^{\ti{\de}^2}}{2}-\frac{(\ti{\ga}^{\ti{\de}}+x^*)^2}{2(\ti{\ga}+1)} \\
	\br{\ga}&=\ti{\ga}+1
	\end{align*}

\subsection{Example: Categorical Distribution}

\subsubsection*{Maximum Likelihood}
Likelihood given by categorical distribution pdf:
	\begin{align*}
	\P{x|\vec{\la}}=\Cat_x[\vec{\la}]=\prod_{j=1}^K\la_j^{x_j}=\la_k
	\end{align*}
Apply maximum likelihood:
	\begin{align*}
	\hat{\vec{\la}}&=\argmax_{\vec{\la}}\prod_{i=1}^I\P{x_i|\vec{\la}} && \text{$s.t. \sum_k\la_k=1$} \\
	&=\argmax_{\vec{\la}}\prod_{i=1}^I\Cat_{x_i}[\vec{\la}] && \text{$s.t. \sum_k\la_k=1$} \\
	&=\argmax_{\vec{\la}}\prod_{k=1}^K\la_k^{N_k} && \text{$s.t. \sum_k\la_k=1$} \\
	&=\argmax_{\vec{\la}}\sum_{k=1}^KN_k\log\la_k && \text{$s.t. \sum_k\la_k=1$}
	\end{align*}
Here, $N_k$ represents the number of times the data is classified in class $k$. As before, we will instead optimize log probability. Since there is a constraint $s.t. \sum_k\la_k=1$, we use Lagrange multiplier to reconstruct the loss function.
	\begin{align*}
	L(\vec{\la})=\sum_{k=1}^KN_k\log\la_k+v\left(\sum_{k=1}^K\la_k-1\right)
	\end{align*}
Let $\grad L(\vec{\la},v)=0$, we have the solution:
	\begin{align*}
	\hat{\la}_k=\frac{N_k}{\sum_{m=1}^KN_m}
	\end{align*}

\subsubsection*{Maximum a Posterior}
Likelihood given by categorical distribution pdf:
	\begin{align*}
	\P{x|\vec{\la}}=\Cat_x[\vec{\la}]=\prod_{j=1}^K\la_j^{x_j}=\la_k
	\end{align*}
Prior given by Dirichlet distribution pdf:
	\begin{align*}
	\P{\vec{\la}}=\Dir_{\vec{\la}}[\vec{\al}]=\frac{\Ga(\sum_{k=1}^K\al_k)}{\prod_{k=1}^K\Ga(\al_k)}\prod_{k=1}^K\la_k^{\al_k-1}
	\end{align*}
Apply maximum a posterior:
	\begin{align*}
	\hat{\vec{\la}}&=\argmax_{\vec{\la}}\prod_{i=1}^I\P{x_i|\vec{\la}}\ \P{\vec{\la}} && \text{$s.t. \sum_k\la_k=1$} \\
	&=\argmax_{\vec{\la}}\Cat_{x_i}[\vec{\la}]\ \Dir_{\vec{\la}}[\vec{\al}] && \text{$s.t. \sum_k\la_k=1$} \\
	&=\argmax_{\vec{\la}}\prod_{k=1}^K\la_k^{N_k}\prod_{k=1}^K\la_k^{\al_k-1} && \text{$s.t. \sum_k\la_k=1$} \\
	&=\argmax_{\vec{\la}}\prod_{k=1}^K\la_k^{N_k+\al_k-1} && \text{$s.t. \sum_k\la_k=1$} \\
	&=\argmax_{\vec{\la}}\sum_{k=1}^K(N_k+\al_k-1)\log\la_k && \text{$s.t. \sum_k\la_k=1$}
	\end{align*}
The loss function is very similar to maximum likelihood (same when the prior is uniform, i.e. $\al_{1\dots k}=1$). Take derivative with Lagrange multiplier, we have the solution:
	\begin{align*}
	\hat{\la}_k=\frac{N_k+\al_k-1}{\sum_{m=1}^K(N_m+\al_m-1)}
	\end{align*}

\subsubsection*{Bayesian Approach}
Compute the posterior distribution using Bayes' rule:
	\begin{align*}
	\P{\vec{\la}|x_{1\dots I}}&=\frac{\prod_{i=1}^I\P{x_i|\vec{\la}}\ \P{\vec{\la}}}{\P{x_{1\dots I}}} \\
	&=\frac{\prod_{i=1}^I\Cat_{x_i}[\vec{\la}]\ \Dir_{\vec{\la}}[\vec{\al}]}{\P{x_{1\dots I}}} \\
	&=\frac{\ka(\vec{\al},x_{1\dots I})\Dir_{\vec{\la}}[\ti{\vec{\al}}]}{\P{x_{1\dots I}}} \\
	&=\Dir_{\vec{\la}}[\ti{\vec{\al}}]
	\end{align*}
Compute predictive distribution:
	\begin{align*}
	\P{x^*|x_{1\dots I}}&=\int\P{x^*|\vec{\la}}\P{\vec{\la}|x_{1\dots I}}d\vec{\la} \\
	&=\int\Cat_{x^*}[\vec{\la}]\Dir_{\vec{\la}}[\ti{\vec{\al}}]d\vec{\la} \\
	&=\int\ka(x^*,\ti{\vec{\al}})\Dir_{\vec{\la}}[\br{\vec{\al}}]d\vec{\la} \\
	&=\ka(x^*,\vec{\al})
	\end{align*}

\section{Machine Learning Models}